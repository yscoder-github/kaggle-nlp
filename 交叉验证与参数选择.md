

https://blog.csdn.net/u014248127/article/details/78899195
​
blog.csdn.net
      
 提到交叉验证不可以不提sklearn里面数据集的划分方法train_test_split，但是这只是数据交叉验证的数据方法，对模型的进行评分。这里我们将对仔细讲解sklearn中交叉验证如何判断模型是否过拟合，并进行参数选择。主要涉及一下方法：

一、cross_validate评估模型的表现：
1，对模型训练一次，然后评估：这样还是会存在过拟合的问题。具体如下：
from sklearn.datasets import load_iris  
import numpy as np 
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
import pandas as pd 
import sys 

iris = load_iris()  
iris_X = iris.data
iris_y = iris.target 

# 测试集占比20% 
# random_state 用于设置随机种子,以保证模型结果可复现
# 默认shuffle为True
X_train, X_test, y_train, y_test = train_test_split(iris_X, iris_y, test_size=0.2, random_state=0)   
knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train, y_train)
print(knn.score(X_test, y_test)) 

解决办法就是把数据分成（训练，验证，测试），但是这样的问题就是会导致数据的浪费。接下来我们用交叉验证的方法评估。
2，cross_val_score方法：
（1）这个方法是对数据进行多次分割，然后训练多个模型并评分，每次分割不一样。之后我们用评分的均值来代表这个模型的得分。方法重要参数是：cv代表计算多少次，分割次数；scoring代表方法。
from sklearn.model_selection import cross_val_score
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=5)
iris = load_iris()  
iris_X = iris.data
iris_y = iris.target 
score = cross_val_score(knn, iris_X, iris_y, cv=5, scoring='accuracy')
print(score)
print(score.mean())

（2）我们可以用这个方法，改变超参数n_neighbors的值，对不同模型进行准确评分，进行参数选择。（代码比较简单，看注释应该可以理解）
from sklearn.datasets import load_iris
from sklearn.neighbors import KNeighborsClassifier
import matplotlib.pyplot as plt

iris = load_iris()
iris_X = iris.data
iris_y = iris.target

#交叉验证
from sklearn.model_selection import cross_val_score
knn = KNeighborsClassifier(n_neighbors=5)
score = cross_val_score(knn, iris_X, iris_y, cv=5, scoring='accuracy')
print(score)
print(score.mean())

#交叉验证对参数进行选择
k_range = range(1,31)
k_loss = []
k_accuracy = []
for k in k_range:  #对参数进行控制，选择参数表现好的，可视化展示
    knn = KNeighborsClassifier(n_neighbors=k)
    accuracy = cross_val_score(knn, iris_X, iris_y, cv=10, scoring='accuracy')#for classification   精度
    loss = -cross_val_score(knn, iris_X, iris_y, cv=10, scoring='neg_mean_squared_error')#for regression    损失函数
    k_accuracy.append(accuracy.mean())#计算均值得分
    k_loss.append(loss.mean())
#绘图
plt.subplot(1, 2, 1)
plt.plot(k_range, k_accuracy)
plt.xlabel("Value of K for KNN")
plt.ylabel("Cross-validates Accuracy")
plt.subplot(1, 2, 2)
plt.plot(k_range, k_loss)
plt.xlabel("Value of K for KNN")
plt.ylabel("Cross-validates Loss")
plt.show()



损失图

下面参考文章
基于sklearn和keras的数据切分与交叉验证 - 焦距 - 博客园
​
www.cnblogs.com
 在训练深度学习模型的时候，通常将数据集切分为训练集和验证集．Keras提供了两种评估模型性能的方法：
使用自动切分的验证集
使用手动切分的验证集
一．自动切分
在Keras中，可以从数据集中切分出一部分作为验证集，并且在每次迭代(epoch)时在验证集中评估模型的性能．
具体地，调用model.fit()训练模型时，可通过validation_split参数来指定从数据集中切分出验证集的比例．
from sklearn.datasets import load_iris
from sklearn.neighbors import KNeighborsClassifier
import matplotlib.pyplot as plt
import sys 
import numpy as np 
from keras.models import Sequential
from keras.layers import Dense
iris = load_iris()
iris_X = iris.data
iris_y = iris.target

np.random.seed(0)
np.random.shuffle(iris_X)
np.random.seed(0)
np.random.shuffle(iris_y)

np.random.seed(7) # fix random seed for reproducibility
# create model
model = Sequential()
model.add(Dense(8, input_dim=4, activation='relu'))
model.add(Dense(6, activation='relu'))
model.add(Dense(4, activation='softmax'))
# Compile model
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
# Fit the model
model.fit(iris_X, iris_y, validation_split=0.20, epochs=80, batch_size=10)
validation_split：0~1之间的浮点数，用来指定训练集的一定比例数据作为验证集。验证集将不参与训练，并在每个epoch结束后测试的模型的指标，如损失函数、精确度等。
注意，validation_split的划分在shuffle之前，因此如果你的数据本身是有序的，需要先手工打乱再指定validation_split，否则可能会出现验证集样本不均匀。 

二．手动切分
Keras允许在训练模型的时候手动指定验证集．
例如，用sklearn库中的train_test_split()函数将数据集进行切分，然后在keras的model.fit()的时候通过validation_data参数指定前面切分出来的验证集．
from sklearn.datasets import load_iris
from sklearn.neighbors import KNeighborsClassifier
import matplotlib.pyplot as plt
import sys 
import numpy as np 
from keras.models import Sequential
from keras.layers import Dense
from sklearn.model_selection import train_test_split
iris = load_iris()
iris_X = iris.data
iris_y = iris.target
print(iris_y)



X_train, X_test, y_train, y_test = train_test_split(iris_X, iris_y, test_size=0.20, random_state=7)

np.random.seed(7)
# create model
model = Sequential()
model.add(Dense(8, input_dim=4, activation='relu'))
model.add(Dense(6, activation='relu'))
model.add(Dense(3, activation='sigmoid'))
# Compile model
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
# Fit the model
model.fit(X_train, y_train, validation_data=(X_test ,y_test), epochs=100, batch_size=10)

三．K折交叉验证（k-fold cross validation）
将数据集分成k份，每一轮用其中(k-1)份做训练而剩余1份做验证，以这种方式执行k轮，得到k个模型．将k次的性能取平均，作为该算法的整体性能．k一般取值为5或者10．
优点：能比较鲁棒性地评估模型在未知数据上的性能．
缺点：计算复杂度较大．因此，在数据集较大，模型复杂度较高，或者计算资源不是很充沛的情况下，可能不适用，尤其是在训练深度学习模型的时候．
sklearn.model_selection提供了KFold以及RepeatedKFold, LeaveOneOut, LeavePOut, ShuffleSplit, StratifiedKFold, GroupKFold, TimeSeriesSplit等变体．
下面的例子中用的StratifiedKFold采用的是分层抽样，它保证各类别的样本在切割后每一份小数据集中的比例都与原数据集中的比例相同．
from sklearn.datasets import load_iris
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import StratifiedKFold
import matplotlib.pyplot as plt
import sys 
import numpy as np 
from keras.models import Sequential
from keras.layers import Dense
from sklearn.model_selection import train_test_split
iris = load_iris()
iris_X = iris.data
iris_y = iris.target
print(iris_y)


# fix random seed for reproducibility
seed = 7
np.random.seed(seed)
kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)
cvscores = []
for train, test in kfold.split(iris_X, iris_y):

    # define 10-fold cross validation test harness
    # create model
    model = Sequential()
    model.add(Dense(8, input_dim=4, activation='relu'))
    model.add(Dense(6, activation='relu'))
    model.add(Dense(3, activation='sigmoid'))
    # Compile model
    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    # Fit the model
    model.fit(iris_X[train], iris_y[train], epochs=100, batch_size=10, verbose=0)
    # evaluate the model
    scores = model.evaluate(iris_X[test], iris_y[test], verbose=0)
    print("%s: %.2f%%" % (model.metrics_names[1], scores[1] * 100))
    cvscores.append(scores[1] * 100)
print("%.2f%% (+/- %.2f%%)" % (np.mean(cvscores), np.std(cvscores)))


