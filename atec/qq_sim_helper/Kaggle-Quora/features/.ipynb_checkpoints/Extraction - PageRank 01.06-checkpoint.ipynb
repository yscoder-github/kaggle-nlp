{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import re\n",
    "import nltk\n",
    "import csv\n",
    "import gensim\n",
    "import math\n",
    "import timeit\n",
    "import datetime\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, ngrams\n",
    "from tqdm import tqdm\n",
    "from pylab import plot, show, subplot, specgram, imshow, savefig\n",
    "from gensim import corpora, models, similarities\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_qid_graph_table(row):\n",
    "    hash_key1 = row[\"q1_hash\"]\n",
    "    hash_key2 = row[\"q2_hash\"]\n",
    "    qid_graph.setdefault(hash_key1, []).append(hash_key2)\n",
    "    qid_graph.setdefault(hash_key2, []).append(hash_key1)\n",
    "    return\n",
    "\n",
    "def pagerank():\n",
    "    MAX_ITER = 20 #Let me know if you find an optimal iteration number!\n",
    "    d = 0.85\n",
    "    pagerank_dict = {i:1/len(qid_graph) for i in qid_graph}\n",
    "    num_nodes = len(pagerank_dict)\n",
    "    for iter in range(0, MAX_ITER):\n",
    "        for node in tqdm(qid_graph):    \n",
    "            local_pr = 0\n",
    "            for neighbor in qid_graph[node]:\n",
    "                local_pr += pagerank_dict[neighbor]/len(qid_graph[neighbor])\n",
    "            pagerank_dict[node] = (1-d)/num_nodes + d*local_pr\n",
    "    return pagerank_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/scripts/features/'\n",
    "train_orig =  pd.read_csv(src + 'df_train_spacylemmat_fullclean.csv').iloc[:, :-1]\n",
    "test_orig =  pd.read_csv(src + 'df_test_spacylemmat_fullclean.csv').iloc[:, 4:]\n",
    "#train_orig =  pd.read_csv(src + 'df_train_lemmatfullcleanSTEMMED.csv').iloc[:, :-1]\n",
    "#test_orig =  pd.read_csv(src + 'df_test_lemmatfullcleanSTEMMED.csv').iloc[:, 4:]\n",
    "\n",
    "tic0=timeit.default_timer()\n",
    "df1 = train_orig[['question1']].copy()\n",
    "df2 = train_orig[['question2']].copy()\n",
    "df1_test = test_orig[['question1']].copy()\n",
    "df2_test = test_orig[['question2']].copy()\n",
    "\n",
    "df2.rename(columns = {'question2':'question1'},inplace=True)\n",
    "df2_test.rename(columns = {'question2':'question1'},inplace=True)\n",
    "\n",
    "train_questions = df1.append(df2)\n",
    "train_questions = train_questions.append(df1_test)\n",
    "train_questions = train_questions.append(df2_test)\n",
    "#train_questions.drop_duplicates(subset = ['qid1'],inplace=True)\n",
    "train_questions.drop_duplicates(subset = ['question1'],inplace=True)\n",
    "\n",
    "train_questions.reset_index(inplace=True,drop=True)\n",
    "questions_dict = pd.Series(train_questions.index.values,index=train_questions.question1.values).to_dict()\n",
    "train_cp = train_orig.copy()\n",
    "test_cp = test_orig.copy()\n",
    "train_cp.drop(['qid1','qid2'],axis=1,inplace=True)\n",
    "\n",
    "test_cp['is_duplicate'] = -1\n",
    "test_cp.rename(columns={'test_id':'id'},inplace=True)\n",
    "comb = pd.concat([train_cp,test_cp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4738787/4738787 [00:05<00:00, 838500.26it/s] \n",
      "100%|██████████| 4738787/4738787 [00:05<00:00, 820165.62it/s] \n",
      "100%|██████████| 4738787/4738787 [00:05<00:00, 839094.53it/s] \n",
      "100%|██████████| 4738787/4738787 [00:05<00:00, 836807.34it/s] \n",
      "100%|██████████| 4738787/4738787 [00:05<00:00, 819037.54it/s] \n",
      "100%|██████████| 4738787/4738787 [00:05<00:00, 816982.18it/s] \n",
      "100%|██████████| 4738787/4738787 [00:06<00:00, 745550.08it/s]\n",
      "100%|██████████| 4738787/4738787 [00:05<00:00, 799403.67it/s] \n",
      "100%|██████████| 4738787/4738787 [00:05<00:00, 821648.27it/s] \n",
      "100%|██████████| 4738787/4738787 [00:06<00:00, 777170.07it/s] \n",
      "100%|██████████| 4738787/4738787 [00:06<00:00, 783990.95it/s] \n",
      "100%|██████████| 4738787/4738787 [00:06<00:00, 781386.52it/s]\n",
      "100%|██████████| 4738787/4738787 [00:05<00:00, 835400.41it/s] \n",
      "100%|██████████| 4738787/4738787 [00:05<00:00, 830281.62it/s] \n",
      "100%|██████████| 4738787/4738787 [00:05<00:00, 801938.14it/s] \n",
      "100%|██████████| 4738787/4738787 [00:05<00:00, 803921.60it/s] \n",
      "100%|██████████| 4738787/4738787 [00:05<00:00, 812474.64it/s] \n",
      "100%|██████████| 4738787/4738787 [00:05<00:00, 833694.55it/s] \n",
      "100%|██████████| 4738787/4738787 [00:05<00:00, 832254.03it/s] \n",
      "100%|██████████| 4738787/4738787 [00:05<00:00, 837957.17it/s] \n"
     ]
    }
   ],
   "source": [
    "comb['q1_hash'] = comb['question1'].map(questions_dict)\n",
    "comb['q2_hash'] = comb['question2'].map(questions_dict)\n",
    "\n",
    "qid_graph = {}\n",
    "comb.apply(generate_qid_graph_table, axis = 1)\n",
    "pagerank_dict = pagerank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comb['q1_pagerank'] = comb['q1_hash'].map(pagerank_dict)\n",
    "comb['q2_pagerank'] = comb['q2_hash'].map(pagerank_dict)\n",
    "\n",
    "train_comb = comb[comb['is_duplicate'] >= 0][['q1_pagerank', 'q2_pagerank']]\n",
    "test_comb = comb[comb['is_duplicate'] < 0][['q1_pagerank', 'q2_pagerank']]\n",
    "\n",
    "train_comb.to_csv('train_PageRankLemmat.csv', index = False)\n",
    "test_comb.to_csv('test_PageRankLemmat.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
