{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "import community\n",
    "\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_match_share(q1, q2, stops=None):\n",
    "    q1 = str(q1).lower().split()\n",
    "    q2 = str(q2).lower().split()\n",
    "    q1words = {}\n",
    "    q2words = {}\n",
    "    for word in q1:\n",
    "        if word not in stops:\n",
    "            q1words[word] = 1\n",
    "    for word in q2:\n",
    "        if word not in stops:\n",
    "            q2words[word] = 1\n",
    "    if len(q1words) == 0 or len(q2words) == 0:\n",
    "        # The computer-generated chaff includes a few questions that are nothing but stopwords\n",
    "        return 0.\n",
    "    shared_words_in_q1 = [w for w in q1words.keys() if w in q2words]\n",
    "    shared_words_in_q2 = [w for w in q2words.keys() if w in q1words]\n",
    "    R = (len(shared_words_in_q1) + len(shared_words_in_q2))/(len(q1words) + len(q2words))\n",
    "    return R\n",
    "\n",
    "def q1_q2_intersect(row):\n",
    "    return(len(set(q_dict[row['question1']]).intersection(set(q_dict[row['question2']]))))\n",
    "\n",
    "def q1_q2_wm_ratio(row):\n",
    "    q1 = q_dict[row['question1']]\n",
    "    q2 = q_dict[row['question2']]\n",
    "    inter_keys = set(q1.keys()).intersection(set(q2.keys()))\n",
    "    if(len(inter_keys) == 0): return 0.\n",
    "    inter_wm = 0.\n",
    "    total_wm = 0.\n",
    "    for q,wm in q1.items():\n",
    "        if q in inter_keys:\n",
    "            inter_wm += wm\n",
    "        total_wm += wm\n",
    "    for q,wm in q2.items():\n",
    "        if q in inter_keys:\n",
    "            inter_wm += wm\n",
    "        total_wm += wm\n",
    "    if(total_wm == 0.): return 0.\n",
    "    return inter_wm/total_wm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/scripts/features/'\n",
    "\n",
    "#trdf =  pd.read_csv(src + 'df_train_spacylemmat_fullclean.csv').iloc[:, :-1]\n",
    "#tedf =  pd.read_csv(src + 'df_test_spacylemmat_fullclean.csv').iloc[:, 4:]\n",
    "\n",
    "#train_orig =  pd.read_csv(src + 'df_train_NER.csv')\n",
    "#test_orig =  pd.read_csv(src + 'df_test_NER.csv')\n",
    "\n",
    "train_orig =  pd.read_csv(src + 'df_train_lemmatfullcleanSTEMMED.csv').iloc[:, :-1]\n",
    "test_orig =  pd.read_csv(src + 'df_test_lemmatfullcleanSTEMMED.csv').iloc[:, 4:]\n",
    "\n",
    "ques = pd.concat([train_orig[['question1', 'question2']], \\\n",
    "        test_orig[['question1', 'question2']]], axis=0).reset_index(drop='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = set(stopwords.words(\"english\"))\n",
    "q_dict = defaultdict(dict)\n",
    "for i in range(ques.shape[0]):\n",
    "        wm = word_match_share(ques.question1[i], ques.question2[i], stops=stops)\n",
    "        q_dict[ques.question1[i]][ques.question2[i]] = wm\n",
    "        q_dict[ques.question2[i]][ques.question1[i]] = wm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_orig['q1_q2_wm_ratio_stem'] = train_orig.apply(q1_q2_wm_ratio, axis=1, raw=True)\n",
    "test_orig['q1_q2_wm_ratio_stem'] = test_orig.apply(q1_q2_wm_ratio, axis=1, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_wm = train_orig[['q1_q2_wm_ratio_stem']]\n",
    "te_wm = test_orig[['q1_q2_wm_ratio_stem']]\n",
    "\n",
    "tr_wm.to_pickle('train_WMratio_stem.pkl')\n",
    "te_wm.to_pickle('test_WMratio_stem.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
