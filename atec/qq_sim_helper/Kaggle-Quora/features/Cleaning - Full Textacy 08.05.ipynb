{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "import pickle\n",
    "import glob\n",
    "import os\n",
    "import string\n",
    "import gc\n",
    "import re\n",
    "import time\n",
    "import nltk\n",
    "import spacy\n",
    "import textacy\n",
    "import en_core_web_md\n",
    "import sematch\n",
    "import gensim\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from scipy import sparse\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from cleaning_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_quora(src):\n",
    "    print('Loading Quora dataset.')\n",
    "    df_train = pd.read_csv(src + 'train.csv')\n",
    "    df_train['test_id'] = -1\n",
    "    df_test = pd.read_csv(src + 'test.csv')\n",
    "    df_test['id'] = -1\n",
    "    df_test['qid1'] = -1\n",
    "    df_test['qid2'] = -1\n",
    "    df_test['is_duplicate'] = -1\n",
    "    df = pd.concat([df_train, df_test])\n",
    "    df['question1'] = df['question1'].fillna('')\n",
    "    df['question2'] = df['question2'].fillna('')\n",
    "    df['uid'] = np.arange(df.shape[0])\n",
    "    df = df.set_index(['uid'])\n",
    "    shapes = (df_train.shape[0], df_test.shape[0])\n",
    "    print('Dataset loaded,', df_train.shape, df_test.shape)\n",
    "    return df, shapes\n",
    "\n",
    "def clean_lemmat_quora(src):\n",
    "    t = time.time()\n",
    "    df, shapes = load_quora(src)\n",
    "    print('Cleaning based on forums functions.')\n",
    "    df = clean_part1(df)\n",
    "    df = clean_part2(df)\n",
    "    print('Cleaning using textacy.')\n",
    "    df.question1 = df.question1.apply(lambda x: textacy.preprocess.preprocess_text(x, fix_unicode = True,\n",
    "                                                                            lowercase = True,\n",
    "                                                                            no_contractions = True,\n",
    "                                                                            transliterate = True))\n",
    "    df.question2 = df.question2.apply(lambda x: textacy.preprocess.preprocess_text(x, fix_unicode = True,\n",
    "                                                                            lowercase = True,\n",
    "                                                                            no_contractions = True,\n",
    "                                                                            transliterate = True))\n",
    "    print('Lemmatizing text.')\n",
    "    SYMBOLS = set(' '.join(string.punctuation).split(' ') + ['...', '“', '”', '\\'ve'])\n",
    "    q1 = []\n",
    "    for doc in tqdm(nlp.pipe(df['question1'], n_threads=8, batch_size=10000)):\n",
    "        word_list = ([c.lemma_ for c in doc if c.lemma_ not in SYMBOLS])\n",
    "        q1.append(' '.join(i for i in word_list))\n",
    "    q2 = []\n",
    "    for doc in tqdm(nlp.pipe(df['question2'], n_threads=8, batch_size=10000)):\n",
    "        word_list = ([c.lemma_ for c in doc if c.lemma_ not in SYMBOLS])\n",
    "        q2.append(' '.join(i for i in word_list))\n",
    "    q1 = pd.DataFrame(q1)\n",
    "    q2 = pd.DataFrame(q2)\n",
    "    df['question1'] = q1\n",
    "    df['question2'] = q2\n",
    "    print('Correcting words. Using most probable substitutes.')\n",
    "    df.question1 = df.question1.apply(lambda x: (' '.join([correction(i) for i in word_tokenize(x)])))\n",
    "    df.question2 = df.question2.apply(lambda x: (' '.join([correction(i) for i in word_tokenize(x)])))\n",
    "    df_train = df.iloc[:shapes[0], :]\n",
    "    df_test = df.iloc[shapes[0]:, :]\n",
    "    print('Text cleaning done, time it took:', time.time() - t)\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('../../data/embeddings/GoogleNews-vectors-negative300.bin', \n",
    "                                                        binary=True)\n",
    "words = model.index2word\n",
    "w_rank = {}\n",
    "for i,word in enumerate(words):\n",
    "    w_rank[word] = i\n",
    "WORDS = w_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Quora dataset.\n",
      "Dataset loaded, (404290, 7) (2345796, 7)\n",
      "Cleaning based on forums functions.\n",
      "Cleaning using textacy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatizing text.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2750086it [07:31, 6086.26it/s]\n",
      "2750086it [07:34, 6055.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correcting words. Using most probable substitutes.\n",
      "Text cleaning done, time it took: 2688.0724029541016\n"
     ]
    }
   ],
   "source": [
    "src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/data/'\n",
    "nlp = en_core_web_md.load()\n",
    "df_train, df_test = clean_lemmat_quora(src)\n",
    "\n",
    "df_train.to_csv('df_train_spacylemmat_fullclean.csv', index = False)\n",
    "df_test.to_csv('df_test_spacylemmat_fullclean.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
