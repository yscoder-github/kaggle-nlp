{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import multiprocessing\n",
    "import difflib\n",
    "import time\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.metrics import log_loss\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from models_utils_fe import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/scripts/features/'\n",
    "feats_src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/data/features/uncleaned/'\n",
    "\n",
    "wmd = pd.read_csv(src + 'train_WMD_cleaned_stemmed.csv')\n",
    "wmd = wmd.astype('float32')\n",
    "wmd.replace(np.inf, 1000, inplace = True)\n",
    "\n",
    "skip_thought = pd.read_csv(src + 'train_skipthoughts_Alex_distances.csv')\n",
    "skip_thought = skip_thought.astype('float32')\n",
    "\n",
    "compression = pd.read_csv(src + 'train_LZMAcompression_distance.csv')\n",
    "compression = compression.astype('float32')\n",
    "\n",
    "edit = pd.read_csv(src + 'train_EDITdistance.csv')\n",
    "edit = edit.astype('float32')\n",
    "\n",
    "moments = pd.read_csv(src + 'train_doc2vec_moments.csv')\n",
    "moments = moments.astype('float32')\n",
    "\n",
    "networks_NER = pd.read_csv(src + 'train_networkfeats_NER.csv')\n",
    "networks_NER = networks_NER.astype('float32')\n",
    "\n",
    "xgb_feats = pd.read_csv(feats_src + '/the_1owl/owl_train.csv')\n",
    "y_train = xgb_feats[['is_duplicate']]\n",
    "\n",
    "X_train = pd.read_pickle('Xtrain_500bestCols.pkl')\n",
    "X_train = pd.concat([X_train, wmd, skip_thought, compression, edit, moments, networks_NER], axis = 1)\n",
    "\n",
    "del xgb_feats, wmd, skip_thought, compression, edit, moments, networks_NER\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_cols = [\n",
    "    'min_pagerank_sp_network_weighted',\n",
    "    'norm_wmd',\n",
    "    'word_match',\n",
    "    '1wl_tfidf_l2_euclidean',\n",
    "    'm_vstack_svd_q1_q1_euclidean',\n",
    "    '1wl_tfidf_cosine',\n",
    "    'sk_bi_skew_q2vec',\n",
    "    'm_q1_q2_tf_svd0',\n",
    "    'sk_bi_skew_q1vec',\n",
    "    'skew_q2vec',\n",
    "    'trigram_tfidf_cosine',\n",
    "    'sk_uni_skew_q2vec',\n",
    "    'sk_bi_canberra_distance',\n",
    "    'question1_3',\n",
    "    'sk_uni_skew_q1vec',\n",
    "    'sk_uni_kur_q2vec',\n",
    "    'min_eigenvector_centrality_np_network_weighted',\n",
    "    'avg_world_len2',\n",
    "    'z_word_match',\n",
    "    'sk_uni_kur_q1vec',\n",
    "    'skew_doc2vec_pretrained_lemmat']\n",
    "\n",
    "rescale = False\n",
    "X_bin = bin_numerical(X_train, best_cols, 0.1)\n",
    "X_grouped = group_featbyfeat(X_train, best_cols, 'mean')\n",
    "X_grouped2 = group_featbyfeat(X_train, best_cols, 'sum')\n",
    "X_combinations = feature_combinations(X_train, best_cols[:5])\n",
    "\n",
    "X_additional = pd.concat([X_bin, X_grouped, X_grouped2, X_combinations], axis = 1)\n",
    "X_additional = drop_duplicate_cols(X_additional)\n",
    "X_additional.replace(np.inf, 999, inplace = True)\n",
    "X_additional.replace(np.nan, -999, inplace = True)\n",
    "if rescale:\n",
    "    colnames = X_additional.columns\n",
    "    X_additional = pd.DataFrame(MinMaxScaler().fit_transform(X_additional))\n",
    "    X_additional.columns = colnames\n",
    "\n",
    "X_train = pd.concat([X_train, X_additional], axis = 1)\n",
    "print('Final training data shape:', X_train.shape)\n",
    "\n",
    "del X_bin, X_grouped, X_grouped2, X_combinations, X_additional\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'task' : 'train',\n",
    "    'boosting_type' : 'gbdt',\n",
    "    'objective' : 'binary',\n",
    "    'metric' : {'binary_logloss'},\n",
    "    'learning_rate' : 0.02,\n",
    "    'feature_fraction' : 0.7,\n",
    "    'bagging_fraction': 0.9,\n",
    "    'bagging_freq': 100,\n",
    "    'num_leaves' : 255,\n",
    "    'max_depth': 12,\n",
    "    'min_data_in_leaf': 20,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'silent': 1,\n",
    "    'random_state': 1337,\n",
    "    'verbose': 1,\n",
    "    'nthread': 9,\n",
    "}\n",
    "\n",
    "t = time.time()\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, stratify = y_train,\n",
    "                                                test_size = 0.2, random_state = 111)\n",
    "lgb_train = lgb.Dataset(X_tr, y_tr.is_duplicate.values)\n",
    "lgb_val = lgb.Dataset(X_val, y_val.is_duplicate.values)\n",
    "\n",
    "print('Start training...')\n",
    "gbm = lgb.train(params, lgb_train, num_boost_round = 100000, valid_sets = lgb_val,\n",
    "                early_stopping_rounds = 150, verbose_eval = 100)\n",
    "\n",
    "print('Start predicting...')\n",
    "val_pred = gbm.predict(X_val, num_iteration=gbm.best_iteration)\n",
    "score = log_loss(y_val, val_pred)\n",
    "print('Final score:', score, '\\n', 'Time it took to train and predict:', time.time() - t)\n",
    "gbm.save_model('saved_models/LGBM/LGBM_500bestexperiments_loss{:.5f}.txt'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
