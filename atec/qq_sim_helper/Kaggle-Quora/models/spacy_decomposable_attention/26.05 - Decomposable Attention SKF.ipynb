{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from __future__ import division, unicode_literals, print_function\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import gc\n",
    "import spacy\n",
    "import plac\n",
    "import time\n",
    "import ujson as json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import en_core_web_md\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except ImportError:\n",
    "    import pickle\n",
    "\n",
    "from spacy_hook import get_embeddings, get_word_ids\n",
    "from spacy_hook import create_similarity_pipeline\n",
    "from keras_decomposable_attention import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attention_foldrun(X, X2, y, name, Xte = None, Xte2 = None, start_fold = 0):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits = 10, random_state = 111, shuffle = True)\n",
    "    if isinstance(X, pd.core.frame.DataFrame):\n",
    "        X = X.values\n",
    "    if isinstance(y, pd.core.frame.DataFrame):\n",
    "        y = y.is_duplicate.values\n",
    "    if isinstance(y, pd.core.frame.Series):\n",
    "        y = y.values\n",
    "    print('Running Decomposable Attention model with parameters:', settings)\n",
    "    \n",
    "    i = 1\n",
    "    losses = []\n",
    "    train_splits = []\n",
    "    val_splits = []\n",
    "    for tr_index, val_index in skf.split(X, y):\n",
    "        train_splits.append(tr_index)\n",
    "        val_splits.append(val_index)\n",
    "        \n",
    "    for i in range(start_fold, 10):\n",
    "        X_trq1, X_valq1 = X[train_splits[i]], X[val_splits[i]]\n",
    "        X_trq2, X_valq2 = X2[train_splits[i]], X2[val_splits[i]]\n",
    "        y_tr, y_val = y[train_splits[i]], y[val_splits[i]]\n",
    "        y_tr = to_categorical(y_tr)\n",
    "        y_val = to_categorical(y_val)\n",
    "        t = time.time()\n",
    "        \n",
    "        print('Start training on fold: {}'.format(i))\n",
    "        callbacks = [ModelCheckpoint('checks/decomposable_{}_10SKF_fold{}.h5'.format(i, name),\n",
    "                                    monitor='val_loss', \n",
    "                                    verbose = 0, save_best_only = True),\n",
    "                 EarlyStopping(monitor='val_loss', patience = 4, verbose = 1)]\n",
    "        \n",
    "        model = build_model(get_embeddings(nlp.vocab), shape, settings)\n",
    "        model.fit([X_trq1, X_trq2], y_tr, validation_data=([X_valq1, X_valq2], y_val),\n",
    "        nb_epoch=settings['nr_epoch'], batch_size=settings['batch_size'], callbacks = callbacks)\n",
    "        val_pred = model.predict([X_valq1, X_valq2], batch_size = 64)\n",
    "        score = log_loss(y_val, val_pred)\n",
    "        losses.append(score)\n",
    "        \n",
    "        print('Predicting training set.')\n",
    "        val_pred = pd.DataFrame(val_pred, index = val_splits[i])\n",
    "        val_pred.columns = ['attention_feat1', 'attention_feat2']\n",
    "        val_pred.to_pickle('OOF_preds/train_attentionpreds_fold{}.pkl'.format(i))\n",
    "        print(val_pred.head())\n",
    "        if Xte is not None:\n",
    "            print('Predicting test set.')\n",
    "            test_preds = model.predict([Xte, Xte2], batch_size = 64)\n",
    "            test_preds = pd.DataFrame(test_preds)\n",
    "            test_preds.columns = ['attention_feat1', 'attention_feat2']\n",
    "            test_preds.to_pickle('OOF_preds/test_attentionpreds_fold{}.pkl'.format(i))\n",
    "            del test_preds\n",
    "            gc.collect()\n",
    "            \n",
    "        print('Final score for fold {} :'.format(i), score, '\\n',\n",
    "              'Time it took to train and predict on fold:', time.time() - t, '\\n')\n",
    "        del X_trq1, X_valq1, X_trq2, X_valq2, y_tr, y_val, val_pred\n",
    "        gc.collect()\n",
    "        i += 1\n",
    "    print('Mean logloss for model in 10-folds SKF:', np.array(losses).mean(axis = 0))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qsrc = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/data/features/lemmatized_fullclean/'\n",
    "qsrc2 = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/data/features/NER/'\n",
    "feats_src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/data/features/uncleaned/'\n",
    "\n",
    "xgb_feats = pd.read_csv(feats_src + '/the_1owl/owl_train.csv')\n",
    "y = xgb_feats.is_duplicate.values\n",
    "\n",
    "nlp = en_core_web_md.load()\n",
    "\n",
    "del xgb_feats\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q1n = np.load(qsrc2 + 'q1train_NER_128len.npy')\n",
    "q2n = np.load(qsrc2 + 'q2train_NER_128len.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "settings = {\n",
    "    'lr': 0.0005,\n",
    "    'dropout': 0.2,\n",
    "    'batch_size': 128,\n",
    "    'nr_epoch': 1,\n",
    "    'tree_truncate': True,\n",
    "    'gru_encode': False,\n",
    "    }\n",
    "\n",
    "max_length = 128\n",
    "nr_hidden = 256\n",
    "shape = (max_length, nr_hidden, 2)\n",
    "print('Shape setting:', shape)\n",
    "\n",
    "q1n = np.load(qsrc2 + 'q1train_NER_128len.npy')\n",
    "q2n = np.load(qsrc2 + 'q2train_NER_128len.npy')\n",
    "q1nte = np.load(qsrc2 + 'q1test_NER_128len.npy')\n",
    "q2nte = np.load(qsrc2 + 'q2test_NER_128len.npy')\n",
    "\n",
    "attention_foldrun(q1n[:1000], q2n[:1000], y[:1000], 'NER128len_2ndrun', start_fold = 0)\n",
    "#attention_foldrun(q1n, q2n, y, 'NER128len_2ndrun', q1nte, q2nte, start_fold = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "settings = {\n",
    "    'lr': 0.0005,\n",
    "    'dropout': 0.2,\n",
    "    'batch_size': 64,\n",
    "    'nr_epoch': 100,\n",
    "    'tree_truncate': True,\n",
    "    'gru_encode': False,\n",
    "    }\n",
    "\n",
    "max_length = 170\n",
    "nr_hidden = 256\n",
    "shape = (max_length, nr_hidden, 2)\n",
    "print('Shape setting:', shape)\n",
    "\n",
    "q1 = np.load(qsrc + 'q1train_spacylemmat_fullclean_170len_treetrunc.npy')\n",
    "q2 = np.load(qsrc + 'q2train_spacylemmat_fullclean_170len_treetrunc.npy')\n",
    "q1te = np.load(qsrc2 + 'q1test_spacylemmat_fullclean_170len_treetrunc.npy')\n",
    "q2te = np.load(qsrc2 + 'q2test_spacylemmat_fullclean_170len_treetrunc.npy')\n",
    "\n",
    "attention_foldrun(q1, q2, y, 'CleanLemmat170len')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
