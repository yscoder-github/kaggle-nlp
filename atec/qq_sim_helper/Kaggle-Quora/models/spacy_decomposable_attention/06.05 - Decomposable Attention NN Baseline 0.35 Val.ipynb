{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "from __future__ import division, unicode_literals, print_function\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import spacy\n",
    "import plac\n",
    "import ujson as json\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import en_core_web_md\n",
    "#import en_vectors_glove_md\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except ImportError:\n",
    "    import pickle\n",
    "\n",
    "from spacy_hook import get_embeddings, get_word_ids\n",
    "from spacy_hook import create_similarity_pipeline\n",
    "from keras_decomposable_attention import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_quora_data(src_train, src_test):\n",
    "    df_train = pd.read_csv(src_train)\n",
    "    df_train.dropna(inplace = True)\n",
    "    df_tr, df_val = train_test_split(df_train, test_size = 0.15, random_state = 111)\n",
    "    return df_tr, df_val\n",
    "\n",
    "def evaluate(dev_loc):\n",
    "    dev_texts1, dev_texts2, dev_labels = read_snli(dev_loc)\n",
    "    nlp = spacy.load('en',\n",
    "            create_pipeline=create_similarity_pipeline)\n",
    "    total = 0.\n",
    "    correct = 0.\n",
    "    for text1, text2, label in zip(dev_texts1, dev_texts2, dev_labels):\n",
    "        doc1 = nlp(text1)\n",
    "        doc2 = nlp(text2)\n",
    "        sim = doc1.similarity(doc2)\n",
    "        if sim.argmax() == label.argmax():\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    return correct, total\n",
    "\n",
    "def train_mine(shape, settings, savename):\n",
    "    train_texts1, train_texts2, train_labels = df_tr['question1'], df_tr['question2'], to_categorical(df_tr['is_duplicate'])\n",
    "    dev_texts1, dev_texts2, dev_labels = df_val['question1'], df_val['question2'], to_categorical(df_val['is_duplicate'])\n",
    "    \n",
    "    print(\"Loading spaCy\")\n",
    "    nlp = en_core_web_md.load()\n",
    "    #nlp = en_vectors_glove_md.load()\n",
    "    #nlp = spacy.load('en')\n",
    "    assert nlp.path is not None\n",
    "    \n",
    "    print(\"Compiling network\")\n",
    "    model = build_model(get_embeddings(nlp.vocab), shape, settings)\n",
    "    print(\"Processing texts...\")\n",
    "    Xs = []\n",
    "    for texts in (train_texts1, train_texts2, dev_texts1, dev_texts2):\n",
    "        Xs.append(get_word_ids(list(nlp.pipe(texts, n_threads=20, batch_size=20000)),\n",
    "                         max_length=shape[0],\n",
    "                         rnn_encode=settings['gru_encode'],\n",
    "                         tree_truncate=settings['tree_truncate']))\n",
    "    train_X1, train_X2, dev_X1, dev_X2 = Xs\n",
    "    print(settings)\n",
    "    callbacks = [ModelCheckpoint('{}.h5'.format(savename),\n",
    "                                        monitor='val_loss', \n",
    "                                        verbose = 0, save_best_only = True),\n",
    "                     EarlyStopping(monitor='val_loss', patience = 10, verbose = 1)]\n",
    "    model.fit(\n",
    "        [train_X1, train_X2],\n",
    "        train_labels,\n",
    "        validation_data=([dev_X1, dev_X2], dev_labels),\n",
    "        nb_epoch=settings['nr_epoch'],\n",
    "        batch_size=settings['batch_size'], callbacks = callbacks)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "src_train_raw = '../../../data/train.csv'\n",
    "src_test_raw = '../../../data/test.csv'\n",
    "\n",
    "src_train = '../../../features/df_train_spacy_lemmat.csv'\n",
    "src_test = '../../../features/df_test_spacy_lemmat.csv'\n",
    "\n",
    "settings = {\n",
    "    'lr': 0.0005,\n",
    "    'dropout': 0.2,\n",
    "    'batch_size': 128,\n",
    "    'nr_epoch': 100,\n",
    "    'tree_truncate': True,\n",
    "    'gru_encode': False,\n",
    "    }\n",
    "\n",
    "max_length = 128\n",
    "nr_hidden = 256\n",
    "shape = (max_length, nr_hidden, 2)\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_tr, df_val = get_quora_data(src_train, src_test)\n",
    "train_mine(shape, settings, 'decomposable_encoreweb_0.0005LR_treetrunc_BiRNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
