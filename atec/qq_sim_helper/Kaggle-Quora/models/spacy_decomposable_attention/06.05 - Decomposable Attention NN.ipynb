{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from __future__ import division, unicode_literals, print_function\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import spacy\n",
    "import plac\n",
    "import ujson as json\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import en_core_web_md\n",
    "import en_vectors_glove_md\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except ImportError:\n",
    "    import pickle\n",
    "\n",
    "from spacy_hook import get_embeddings, get_word_ids\n",
    "from spacy_hook import create_similarity_pipeline\n",
    "from keras_decomposable_attention import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_quora_data(src_train, src_test):\n",
    "    df_train = pd.read_csv(src_train)\n",
    "    df_train.dropna(inplace = True)\n",
    "    df_tr, df_val = train_test_split(df_train, test_size = 0.15, random_state = 111)\n",
    "    return df_tr, df_val\n",
    "\n",
    "def evaluate(dev_loc):\n",
    "    dev_texts1, dev_texts2, dev_labels = read_snli(dev_loc)\n",
    "    nlp = spacy.load('en',\n",
    "            create_pipeline=create_similarity_pipeline)\n",
    "    total = 0.\n",
    "    correct = 0.\n",
    "    for text1, text2, label in zip(dev_texts1, dev_texts2, dev_labels):\n",
    "        doc1 = nlp(text1)\n",
    "        doc2 = nlp(text2)\n",
    "        sim = doc1.similarity(doc2)\n",
    "        if sim.argmax() == label.argmax():\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    return correct, total\n",
    "\n",
    "def train_mine(shape, settings, savename):\n",
    "    train_texts1, train_texts2, train_labels = df_tr['question1'], df_tr['question2'], to_categorical(df_tr['is_duplicate'])\n",
    "    dev_texts1, dev_texts2, dev_labels = df_val['question1'], df_val['question2'], to_categorical(df_val['is_duplicate'])\n",
    "    \n",
    "    print(\"Loading spaCy\")\n",
    "    #nlp = spacy.load('en')\n",
    "    nlp = en_core_web_md.load()\n",
    "    #nlp = en_vectors_glove_md.load()\n",
    "    assert nlp.path is not None\n",
    "    \n",
    "    print(\"Compiling network\")\n",
    "    model = build_model(get_embeddings(nlp.vocab), shape, settings)\n",
    "    print(\"Processing texts...\")\n",
    "    Xs = []\n",
    "    for texts in (train_texts1, train_texts2, dev_texts1, dev_texts2):\n",
    "        Xs.append(get_word_ids(list(nlp.pipe(texts, n_threads=20, batch_size=20000)),\n",
    "                         max_length=shape[0],\n",
    "                         rnn_encode=settings['gru_encode'],\n",
    "                         tree_truncate=settings['tree_truncate']))\n",
    "    train_X1, train_X2, dev_X1, dev_X2 = Xs\n",
    "    print(settings)\n",
    "    callbacks = [ModelCheckpoint('{}.h5'.format(savename),\n",
    "                                        monitor='val_loss', \n",
    "                                        verbose = 0, save_best_only = True),\n",
    "                     EarlyStopping(monitor='val_loss', patience = 10, verbose = 1)]\n",
    "    model.fit([train_X1, train_X2],train_labels,\n",
    "        validation_data=([dev_X1, dev_X2], dev_labels), \n",
    "        nb_epoch=settings['nr_epoch'],\n",
    "        batch_size=settings['batch_size'], callbacks = callbacks)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(170, 256, 2)\n"
     ]
    }
   ],
   "source": [
    "src_train_raw = '../../../data/train.csv'\n",
    "src_test_raw = '../../../data/test.csv'\n",
    "\n",
    "src_train = '../../../features/df_train_lemmatfullcleanSTEMMED.csv'\n",
    "src_test = '../../../features/df_test_lemmatfullcleanSTEMMED.csv'\n",
    "\n",
    "settings = {\n",
    "    'lr': 0.0005,\n",
    "    'dropout': 0.2,\n",
    "    'batch_size': 128,\n",
    "    'nr_epoch': 100,\n",
    "    'tree_truncate': False,\n",
    "    'gru_encode': False,\n",
    "    }\n",
    "\n",
    "max_length = 170\n",
    "nr_hidden = 256\n",
    "shape = (max_length, nr_hidden, 2)\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On fullclean data:\n",
    "\n",
    "settings = {\n",
    "    'lr': 0.0005,\n",
    "    'dropout': 0.2,\n",
    "    'batch_size': 128,\n",
    "    'nr_epoch': 100,\n",
    "    'tree_truncate': False,\n",
    "    'gru_encode': False,\n",
    "    }\n",
    "\n",
    "max_length = 170\n",
    "nr_hidden = 256\n",
    "fullclean\n",
    "\n",
    "val_loss: 0.3533 with treetrunc 0.3483"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading spaCy\n",
      "Compiling network\n",
      "Processing texts...\n",
      "{'nr_epoch': 100, 'gru_encode': False, 'lr': 0.0005, 'batch_size': 128, 'dropout': 0.2, 'tree_truncate': False}\n",
      "Train on 343646 samples, validate on 60644 samples\n",
      "Epoch 1/100\n",
      "343646/343646 [==============================] - 235s - loss: 0.4845 - acc: 0.7562 - val_loss: 0.6796 - val_acc: 0.7046\n",
      "Epoch 2/100\n",
      "343646/343646 [==============================] - 244s - loss: 0.4114 - acc: 0.8014 - val_loss: 0.5188 - val_acc: 0.7554\n",
      "Epoch 3/100\n",
      "343646/343646 [==============================] - 244s - loss: 0.3836 - acc: 0.8181 - val_loss: 0.4595 - val_acc: 0.7779\n",
      "Epoch 4/100\n",
      "343646/343646 [==============================] - 244s - loss: 0.3639 - acc: 0.8292 - val_loss: 0.4361 - val_acc: 0.7985\n",
      "Epoch 5/100\n",
      "343646/343646 [==============================] - 233s - loss: 0.3501 - acc: 0.8373 - val_loss: 0.4450 - val_acc: 0.7956\n",
      "Epoch 6/100\n",
      "343646/343646 [==============================] - 245s - loss: 0.3380 - acc: 0.8434 - val_loss: 0.4354 - val_acc: 0.7988\n",
      "Epoch 7/100\n",
      "343646/343646 [==============================] - 244s - loss: 0.3275 - acc: 0.8492 - val_loss: 0.4023 - val_acc: 0.8090\n",
      "Epoch 8/100\n",
      "343646/343646 [==============================] - 244s - loss: 0.3179 - acc: 0.8545 - val_loss: 0.3987 - val_acc: 0.8174\n",
      "Epoch 9/100\n",
      "343646/343646 [==============================] - 245s - loss: 0.3098 - acc: 0.8585 - val_loss: 0.3892 - val_acc: 0.8156\n",
      "Epoch 10/100\n",
      "343646/343646 [==============================] - 244s - loss: 0.3029 - acc: 0.8619 - val_loss: 0.3843 - val_acc: 0.8259\n",
      "Epoch 11/100\n",
      "343646/343646 [==============================] - 234s - loss: 0.2959 - acc: 0.8654 - val_loss: 0.3972 - val_acc: 0.8253\n",
      "Epoch 12/100\n",
      "343646/343646 [==============================] - 244s - loss: 0.2900 - acc: 0.8688 - val_loss: 0.3772 - val_acc: 0.8280\n",
      "Epoch 13/100\n",
      "343646/343646 [==============================] - 233s - loss: 0.2847 - acc: 0.8718 - val_loss: 0.3839 - val_acc: 0.8322\n",
      "Epoch 14/100\n",
      "343646/343646 [==============================] - 234s - loss: 0.2792 - acc: 0.8747 - val_loss: 0.3786 - val_acc: 0.8335\n",
      "Epoch 15/100\n",
      "343646/343646 [==============================] - 245s - loss: 0.2752 - acc: 0.8766 - val_loss: 0.3729 - val_acc: 0.8328\n",
      "Epoch 16/100\n",
      "343646/343646 [==============================] - 243s - loss: 0.2708 - acc: 0.8791 - val_loss: 0.3625 - val_acc: 0.8379\n",
      "Epoch 17/100\n",
      "343646/343646 [==============================] - 233s - loss: 0.2660 - acc: 0.8811 - val_loss: 0.3730 - val_acc: 0.8340\n",
      "Epoch 18/100\n",
      "343646/343646 [==============================] - 233s - loss: 0.2625 - acc: 0.8829 - val_loss: 0.3882 - val_acc: 0.8335\n",
      "Epoch 19/100\n",
      "343646/343646 [==============================] - 233s - loss: 0.2585 - acc: 0.8845 - val_loss: 0.3774 - val_acc: 0.8371\n",
      "Epoch 20/100\n",
      "343646/343646 [==============================] - 232s - loss: 0.2565 - acc: 0.8860 - val_loss: 0.3737 - val_acc: 0.8351\n",
      "Epoch 21/100\n",
      "343646/343646 [==============================] - 233s - loss: 0.2529 - acc: 0.8880 - val_loss: 0.3795 - val_acc: 0.8403\n",
      "Epoch 22/100\n",
      "343646/343646 [==============================] - 233s - loss: 0.2500 - acc: 0.8894 - val_loss: 0.3686 - val_acc: 0.8440\n",
      "Epoch 23/100\n",
      "343646/343646 [==============================] - 232s - loss: 0.2479 - acc: 0.8897 - val_loss: 0.3760 - val_acc: 0.8409\n",
      "Epoch 24/100\n",
      "343646/343646 [==============================] - 232s - loss: 0.2434 - acc: 0.8927 - val_loss: 0.3735 - val_acc: 0.8422\n",
      "Epoch 25/100\n",
      "343646/343646 [==============================] - 232s - loss: 0.2422 - acc: 0.8932 - val_loss: 0.3717 - val_acc: 0.8423\n",
      "Epoch 26/100\n",
      "343646/343646 [==============================] - 232s - loss: 0.2392 - acc: 0.8945 - val_loss: 0.3732 - val_acc: 0.8397\n",
      "Epoch 27/100\n",
      "343646/343646 [==============================] - 232s - loss: 0.2381 - acc: 0.8949 - val_loss: 0.3702 - val_acc: 0.8442\n",
      "Epoch 00026: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7f2d3274d710>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr, df_val = get_quora_data(src_train, src_test)\n",
    "train_mine(shape, settings, 'decomposable_encoreweb_0.0005LR_170len_fullcleanSTEM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
