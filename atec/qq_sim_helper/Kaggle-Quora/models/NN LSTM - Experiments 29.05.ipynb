{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import re\n",
    "import csv\n",
    "import codecs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import sys\n",
    "import gensim\n",
    "import time\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from string import punctuation\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merged_lstm():\n",
    "    embedding_layer = Embedding(nb_words,\n",
    "            embedding_dim,\n",
    "            weights=[word_embedding_matrix],\n",
    "            input_length=seq_length,\n",
    "            trainable=False)\n",
    "    \n",
    "    lstm_layer = LSTM(128, dropout=0.25, recurrent_dropout=0.2,\n",
    "                     go_backwards = False, implementation = 2)\n",
    "\n",
    "    sequence_1_input = Input(shape=(seq_length,), dtype='int32')\n",
    "    embedded_sequences_1 = embedding_layer(sequence_1_input)\n",
    "    x1 = lstm_layer(embedded_sequences_1)\n",
    "\n",
    "    sequence_2_input = Input(shape=(seq_length,), dtype='int32')\n",
    "    embedded_sequences_2 = embedding_layer(sequence_2_input)\n",
    "    y1 = lstm_layer(embedded_sequences_2)\n",
    "\n",
    "    dense_input = Input(shape = (ncols,))\n",
    "    d = Dense(256, kernel_initializer = 'he_normal')(dense_input)\n",
    "    d = PReLU()(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = Dropout(0.4)(d)\n",
    "    \n",
    "    d2 = Dense(512, kernel_initializer = 'he_normal')(d)\n",
    "    d2 = PReLU()(d2)\n",
    "    d2 = BatchNormalization()(d2)\n",
    "    d2 = Dropout(0.2)(d2)\n",
    "    \n",
    "    d3 = Dense(512, kernel_initializer = 'he_normal')(d2)\n",
    "    d3 = PReLU()(d3)\n",
    "    d3 = Dropout(0.2)(d3)\n",
    "    \n",
    "    merged = concatenate([x1, y1, d3])\n",
    "    merged = Dropout(0.25)(merged)\n",
    "    merged = BatchNormalization()(merged)\n",
    "\n",
    "    merged = Dense(256)(merged)\n",
    "    merged = PReLU()(merged)\n",
    "    merged = Dropout(0.25)(merged)\n",
    "    merged = BatchNormalization()(merged)\n",
    "\n",
    "    preds = Dense(1, activation='sigmoid')(merged)\n",
    "    model = Model(inputs=[sequence_1_input, sequence_2_input, dense_input], outputs=preds)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seq_length = 128\n",
    "embedding_dim = 300\n",
    "nb_words = 120594\n",
    "\n",
    "data_src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/data/transformed/keras_tokenizer/'\n",
    "word_embedding_matrix = np.load(data_src + 'embedding_matrix.npy')\n",
    "\n",
    "q_src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/data/features/NER/'\n",
    "feats_src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/data/features/uncleaned/'\n",
    "\n",
    "q1 = np.load(q_src + 'q1train_NER_128len.npy')\n",
    "q2 = np.load(q_src + 'q2train_NER_128len.npy')\n",
    "X_train = pd.read_pickle('Xtrain_866BestColsDropped.pkl')\n",
    "X_train = X_train.astype('float32')\n",
    "X_train = X_train.replace(np.nan, -999)\n",
    "X_train = X_train.replace(np.inf, 999)\n",
    "\n",
    "y = pd.read_csv(feats_src + '/the_1owl/owl_train.csv')['is_duplicate'].values\n",
    "\n",
    "test = False\n",
    "if test:\n",
    "    q1_te = np.load(q_src + 'q1test_NER_128len.npy')\n",
    "    q2_te = np.load(q_src + 'q2test_NER_128len.npy')\n",
    "    X_test = pd.read_pickle('Xtest_814colsBest.pkl', compression = 'bz2')\n",
    "    X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstm_foldrun(X, q1, q2, y, X_test = None, q1_test = None, q2_test = None, start_fold = 0,\n",
    "                name = 'LSTM_merged866cols', save = True):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits = 10, random_state = 111, shuffle = True)\n",
    "    if isinstance(X, pd.core.frame.DataFrame):\n",
    "        X = X.values\n",
    "    if isinstance(X_test, pd.core.frame.DataFrame):\n",
    "        X_test = X_test.values\n",
    "    if isinstance(y, pd.core.frame.DataFrame):\n",
    "        y = y.is_duplicate.values\n",
    "    if isinstance(y, pd.core.frame.Series):\n",
    "        y = y.values\n",
    "    \n",
    "    i = 0\n",
    "    losses = []\n",
    "    train_splits = []\n",
    "    val_splits = []\n",
    "    for tr_index, val_index in skf.split(X, y):\n",
    "        train_splits.append(tr_index)\n",
    "        val_splits.append(val_index)\n",
    "        \n",
    "    oof_train = np.zeros((404290))\n",
    "    oof_test = np.zeros((10, 2345796))\n",
    "    os.makedirs('saved_models/LSTM/SKF/{}'.format(name), exist_ok = True)\n",
    "    for i in range(start_fold, 10):\n",
    "        X_tr, X_val = X[train_splits[i]], X[val_splits[i]]\n",
    "        q1_tr, q1_val = q1[train_splits[i]], q1[val_splits[i]]\n",
    "        q2_tr, q2_val = q2[train_splits[i]], q2[val_splits[i]]\n",
    "        y_tr, y_val = y[train_splits[i]], y[val_splits[i]]\n",
    "\n",
    "        t = time.time()\n",
    "        print('Start training on fold: {}'.format(i))\n",
    "        callbacks = [ModelCheckpoint('saved_models/LSTM/SKF/{}/{}_fold{}.h5'.format(name, name, i),\n",
    "                                    monitor='val_loss', \n",
    "                                    verbose = 0, save_best_only = True),\n",
    "                 EarlyStopping(monitor='val_loss', patience = 7, verbose = 1)]\n",
    "        \n",
    "        model = merged_lstm()\n",
    "        model.fit([q1_tr, q2_tr, X_tr], y_tr, validation_data=([q1_val, q2_val, X_val], y_val),\n",
    "                epochs=200, batch_size=512, callbacks = callbacks)\n",
    "        \n",
    "        val_pred = model.predict([q1_val, q2_val, X_val], batch_size = 64)\n",
    "        oof_train[val_splits[i]] = val_pred\n",
    "        score = log_loss(y_val, val_pred)\n",
    "        losses.append(score)\n",
    "        print('Predicting training set.')\n",
    "        if X_test is not None:\n",
    "            print('Predicting test set.')\n",
    "            test_preds = model.predict([q1_te, q2_te, X_test], batch_size = 64)\n",
    "            oof_test[i, :] = test_preds\n",
    "        print('Final score for fold {} :'.format(i), score, '\\n',\n",
    "              'Time it took to train and predict on fold:', time.time() - t, '\\n')\n",
    "        del X_tr, X_val, q1_tr, q1_val, q2_tr, q2_val\n",
    "        gc.collect()\n",
    "        i += 1\n",
    "        \n",
    "    print('Mean logloss for model in 10-folds SKF:', np.array(losses).mean(axis = 0), '\\n')\n",
    "    oof_train = pd.DataFrame(oof_train)\n",
    "    oof_train.columns = ['{}_prob'.format(name)]\n",
    "    oof_test = oof_test.mean(axis = 0)\n",
    "    oof_test = pd.DataFrame(oof_test)\n",
    "    oof_test.columns = ['{}_prob'.format(name)]\n",
    "    if save:\n",
    "        oof_train.to_pickle('OOF_preds/train/train_preds_{}.pkl'.format(name))\n",
    "        oof_test.to_pickle('OOF_preds/test/test_preds_{}.pkl'.format(name))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training on fold: 9\n",
      "Train on 363862 samples, validate on 40428 samples\n",
      "Epoch 1/200\n",
      "363862/363862 [==============================] - 207s - loss: 0.5196 - acc: 0.7220 - val_loss: 0.4510 - val_acc: 0.7692\n",
      "Epoch 2/200\n",
      "363862/363862 [==============================] - 202s - loss: 0.4389 - acc: 0.7723 - val_loss: 0.3982 - val_acc: 0.7956\n",
      "Epoch 3/200\n",
      "363862/363862 [==============================] - 201s - loss: 0.4004 - acc: 0.7985 - val_loss: 0.3842 - val_acc: 0.8004\n",
      "Epoch 4/200\n",
      "363862/363862 [==============================] - 200s - loss: 0.3833 - acc: 0.8092 - val_loss: 0.3595 - val_acc: 0.8212\n",
      "Epoch 5/200\n",
      "363862/363862 [==============================] - 202s - loss: 0.3733 - acc: 0.8149 - val_loss: 0.3534 - val_acc: 0.8257\n",
      "Epoch 6/200\n",
      "363862/363862 [==============================] - 202s - loss: 0.3636 - acc: 0.8199 - val_loss: 0.3433 - val_acc: 0.8307\n",
      "Epoch 7/200\n",
      "363862/363862 [==============================] - 210s - loss: 0.3552 - acc: 0.8249 - val_loss: 0.3346 - val_acc: 0.8356\n",
      "Epoch 8/200\n",
      "363862/363862 [==============================] - 200s - loss: 0.3508 - acc: 0.8271 - val_loss: 0.3516 - val_acc: 0.8218\n",
      "Epoch 9/200\n",
      "363862/363862 [==============================] - 213s - loss: 0.3452 - acc: 0.8303 - val_loss: 0.3307 - val_acc: 0.8373\n",
      "Epoch 10/200\n",
      "363862/363862 [==============================] - 214s - loss: 0.3411 - acc: 0.8317 - val_loss: 0.3929 - val_acc: 0.7954\n",
      "Epoch 11/200\n",
      "363862/363862 [==============================] - 202s - loss: 0.3370 - acc: 0.8348 - val_loss: 0.3238 - val_acc: 0.8379\n",
      "Epoch 12/200\n",
      "363862/363862 [==============================] - 209s - loss: 0.3359 - acc: 0.8341 - val_loss: 0.3315 - val_acc: 0.8370\n",
      "Epoch 13/200\n",
      "363862/363862 [==============================] - 218s - loss: 0.3318 - acc: 0.8373 - val_loss: 0.3227 - val_acc: 0.8422\n",
      "Epoch 14/200\n",
      "363862/363862 [==============================] - 204s - loss: 0.3312 - acc: 0.8374 - val_loss: 0.3298 - val_acc: 0.8319\n",
      "Epoch 15/200\n",
      "363862/363862 [==============================] - 214s - loss: 0.3289 - acc: 0.8388 - val_loss: 0.3193 - val_acc: 0.8427\n",
      "Epoch 16/200\n",
      "363862/363862 [==============================] - 204s - loss: 0.3282 - acc: 0.8386 - val_loss: 0.3125 - val_acc: 0.8465\n",
      "Epoch 17/200\n",
      "363862/363862 [==============================] - 207s - loss: 0.3244 - acc: 0.8415 - val_loss: 0.3127 - val_acc: 0.8480\n",
      "Epoch 18/200\n",
      "363862/363862 [==============================] - 213s - loss: 0.3233 - acc: 0.8420 - val_loss: 0.3133 - val_acc: 0.8456\n",
      "Epoch 19/200\n",
      "363862/363862 [==============================] - 204s - loss: 0.3204 - acc: 0.8433 - val_loss: 0.3113 - val_acc: 0.8467\n",
      "Epoch 20/200\n",
      "363862/363862 [==============================] - 212s - loss: 0.3216 - acc: 0.8426 - val_loss: 0.3207 - val_acc: 0.8373\n",
      "Epoch 21/200\n",
      "363862/363862 [==============================] - 215s - loss: 0.3222 - acc: 0.8418 - val_loss: 0.3079 - val_acc: 0.8475\n",
      "Epoch 22/200\n",
      "363862/363862 [==============================] - 203s - loss: 0.3187 - acc: 0.8442 - val_loss: 0.3078 - val_acc: 0.8523\n",
      "Epoch 23/200\n",
      "363862/363862 [==============================] - 217s - loss: 0.3171 - acc: 0.8452 - val_loss: 0.3063 - val_acc: 0.8502\n",
      "Epoch 24/200\n",
      "363862/363862 [==============================] - 202s - loss: 0.3174 - acc: 0.8449 - val_loss: 0.3156 - val_acc: 0.8498\n",
      "Epoch 25/200\n",
      "363862/363862 [==============================] - 218s - loss: 0.3145 - acc: 0.8465 - val_loss: 0.3025 - val_acc: 0.8526\n",
      "Epoch 26/200\n",
      "363862/363862 [==============================] - 218s - loss: 0.3135 - acc: 0.8475 - val_loss: 0.3224 - val_acc: 0.8367\n",
      "Epoch 27/200\n",
      "363862/363862 [==============================] - 201s - loss: 0.3115 - acc: 0.8482 - val_loss: 0.3000 - val_acc: 0.8550\n",
      "Epoch 28/200\n",
      "363862/363862 [==============================] - 216s - loss: 0.3100 - acc: 0.8491 - val_loss: 0.3025 - val_acc: 0.8512\n",
      "Epoch 29/200\n",
      "363862/363862 [==============================] - 217s - loss: 0.3086 - acc: 0.8505 - val_loss: 0.2936 - val_acc: 0.8571\n",
      "Epoch 30/200\n",
      "363862/363862 [==============================] - 203s - loss: 0.3076 - acc: 0.8508 - val_loss: 0.2973 - val_acc: 0.8568\n",
      "Epoch 31/200\n",
      "363862/363862 [==============================] - 209s - loss: 0.3068 - acc: 0.8509 - val_loss: 0.3312 - val_acc: 0.8295\n",
      "Epoch 32/200\n",
      "363862/363862 [==============================] - 189s - loss: 0.3058 - acc: 0.8516 - val_loss: 0.2917 - val_acc: 0.8583\n",
      "Epoch 33/200\n",
      "363862/363862 [==============================] - 187s - loss: 0.3045 - acc: 0.8528 - val_loss: 0.3070 - val_acc: 0.8485\n",
      "Epoch 34/200\n",
      "363862/363862 [==============================] - 185s - loss: 0.3069 - acc: 0.8511 - val_loss: 0.3390 - val_acc: 0.8245\n",
      "Epoch 35/200\n",
      "363862/363862 [==============================] - 184s - loss: 0.3069 - acc: 0.8512 - val_loss: 0.2997 - val_acc: 0.8575\n",
      "Epoch 36/200\n",
      "363862/363862 [==============================] - 185s - loss: 0.3045 - acc: 0.8518 - val_loss: 0.2929 - val_acc: 0.8580\n",
      "Epoch 37/200\n",
      "363862/363862 [==============================] - 187s - loss: 0.3035 - acc: 0.8527 - val_loss: 0.2990 - val_acc: 0.8583\n",
      "Epoch 38/200\n",
      "363862/363862 [==============================] - 186s - loss: 0.3017 - acc: 0.8540 - val_loss: 0.3048 - val_acc: 0.8551\n",
      "Epoch 39/200\n",
      "363862/363862 [==============================] - 183s - loss: 0.3026 - acc: 0.8538 - val_loss: 0.2960 - val_acc: 0.8576\n",
      "Epoch 40/200\n",
      "363862/363862 [==============================] - 175s - loss: 0.3014 - acc: 0.8533 - val_loss: 0.2883 - val_acc: 0.8605\n",
      "Epoch 41/200\n",
      "363862/363862 [==============================] - 178s - loss: 0.2986 - acc: 0.8560 - val_loss: 0.2972 - val_acc: 0.8543\n",
      "Epoch 42/200\n",
      "363862/363862 [==============================] - 177s - loss: 0.2997 - acc: 0.8559 - val_loss: 0.2911 - val_acc: 0.8590\n",
      "Epoch 43/200\n",
      "363862/363862 [==============================] - 175s - loss: 0.2984 - acc: 0.8561 - val_loss: 0.2925 - val_acc: 0.8583\n",
      "Epoch 44/200\n",
      "363862/363862 [==============================] - 179s - loss: 0.2970 - acc: 0.8568 - val_loss: 0.2841 - val_acc: 0.8623\n",
      "Epoch 45/200\n",
      "363862/363862 [==============================] - 178s - loss: 0.2966 - acc: 0.8567 - val_loss: 0.2924 - val_acc: 0.8588\n",
      "Epoch 46/200\n",
      "363862/363862 [==============================] - 184s - loss: 0.2981 - acc: 0.8559 - val_loss: 0.2910 - val_acc: 0.8615\n",
      "Epoch 47/200\n",
      "363862/363862 [==============================] - 182s - loss: 0.2960 - acc: 0.8567 - val_loss: 0.2876 - val_acc: 0.8619\n",
      "Epoch 48/200\n",
      "363862/363862 [==============================] - 183s - loss: 0.2944 - acc: 0.8580 - val_loss: 0.2979 - val_acc: 0.8572\n",
      "Epoch 49/200\n",
      "363862/363862 [==============================] - 185s - loss: 0.2944 - acc: 0.8584 - val_loss: 0.2834 - val_acc: 0.8636\n",
      "Epoch 50/200\n",
      "363862/363862 [==============================] - 176s - loss: 0.2938 - acc: 0.8580 - val_loss: 0.2829 - val_acc: 0.8645\n",
      "Epoch 51/200\n",
      "363862/363862 [==============================] - 177s - loss: 0.2937 - acc: 0.8585 - val_loss: 0.2827 - val_acc: 0.8641\n",
      "Epoch 52/200\n",
      "363862/363862 [==============================] - 178s - loss: 0.2942 - acc: 0.8582 - val_loss: 0.2825 - val_acc: 0.8651\n",
      "Epoch 53/200\n",
      "363862/363862 [==============================] - 179s - loss: 0.2928 - acc: 0.8587 - val_loss: 0.2855 - val_acc: 0.8605\n",
      "Epoch 54/200\n",
      "363862/363862 [==============================] - 179s - loss: 0.2927 - acc: 0.8587 - val_loss: 0.2894 - val_acc: 0.8626\n",
      "Epoch 55/200\n",
      "363862/363862 [==============================] - 185s - loss: 0.2921 - acc: 0.8588 - val_loss: 0.2805 - val_acc: 0.8635\n",
      "Epoch 56/200\n",
      "363862/363862 [==============================] - 183s - loss: 0.2916 - acc: 0.8593 - val_loss: 0.2866 - val_acc: 0.8619\n",
      "Epoch 57/200\n",
      "363862/363862 [==============================] - 184s - loss: 0.2913 - acc: 0.8596 - val_loss: 0.2826 - val_acc: 0.8614\n",
      "Epoch 58/200\n",
      "363862/363862 [==============================] - 185s - loss: 0.2904 - acc: 0.8606 - val_loss: 0.2849 - val_acc: 0.8646\n",
      "Epoch 59/200\n",
      "363862/363862 [==============================] - 185s - loss: 0.2899 - acc: 0.8604 - val_loss: 0.2953 - val_acc: 0.8532\n",
      "Epoch 60/200\n",
      "363862/363862 [==============================] - 185s - loss: 0.2907 - acc: 0.8609 - val_loss: 0.2861 - val_acc: 0.8632\n",
      "Epoch 61/200\n",
      "363862/363862 [==============================] - 180s - loss: 0.2902 - acc: 0.8602 - val_loss: 0.2820 - val_acc: 0.8634\n",
      "Epoch 62/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363862/363862 [==============================] - 180s - loss: 0.2897 - acc: 0.8607 - val_loss: 0.2816 - val_acc: 0.8652\n",
      "Epoch 63/200\n",
      "363862/363862 [==============================] - 182s - loss: 0.2898 - acc: 0.8605 - val_loss: 0.2921 - val_acc: 0.8587\n",
      "Epoch 00062: early stopping\n",
      "Predicting training set.\n",
      "Final score for fold 9 : 0.292072590069 \n",
      " Time it took to train and predict on fold: 12354.294585466385 \n",
      "\n",
      "Mean logloss for model in 10-folds SKF: 0.292072590069 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/w/anaconda3/envs/idp3/lib/python3.5/site-packages/ipykernel_launcher.py:43: DeprecationWarning: assignment will raise an error in the future, most likely because your index result shape does not match the value array shape. You can use `arr.flat[index] = values` to keep the old behaviour.\n"
     ]
    }
   ],
   "source": [
    "ncols = X_train.shape[1]\n",
    "lstm_foldrun(X_train, q1, q2, y, start_fold = 9, name = 'LSTM_merged866cols_3rd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
