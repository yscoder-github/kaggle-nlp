{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import difflib\n",
    "import time\n",
    "import gc\n",
    "import itertools\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from models_utils_fe import *\n",
    "from models_utils_skf import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404290, 903)\n",
      "903\n"
     ]
    }
   ],
   "source": [
    "src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/scripts/features/'\n",
    "feats_src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/data/features/uncleaned/'\n",
    "\n",
    "X_train = pd.read_pickle('Xtrain_825colsCurrentBest.pkl')\n",
    "new_set = pd.read_pickle('train_NewSubset_BestAbhishek.pkl')\n",
    "new_set.columns = ['{}_lemmat{}'.format(val, i) for i, val in enumerate(new_set.columns)]\n",
    "new_networks = pd.read_pickle('train_networkfeats_weighted_untransformed_30.05.pkl')\n",
    "\n",
    "for col in new_networks.columns:\n",
    "    X_train[col] = new_networks[col]\n",
    "\n",
    "xgb_feats = pd.read_csv(feats_src + '/the_1owl/owl_train.csv')\n",
    "y_train = xgb_feats[['is_duplicate']]\n",
    "\n",
    "\n",
    "X_train = pd.concat([X_train, new_set], axis = 1)\n",
    "X_train = X_train.astype('float32')\n",
    "print(X_train.shape)\n",
    "print(len(list(set(X_train.columns))))\n",
    "X_train = drop_duplicate_cols(X_train)\n",
    "\n",
    "del xgb_feats, new_set\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.to_pickle('Xtrain_866BestColsDropped.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'task' : 'train',\n",
    "    'boosting_type' : 'gbdt',\n",
    "    'objective' : 'binary',\n",
    "    'metric' : {'binary_logloss'},\n",
    "    'learning_rate' : 0.03,\n",
    "    'feature_fraction' : 0.51,\n",
    "    'bagging_fraction': 0.9,\n",
    "    'bagging_freq': 100,\n",
    "    'num_leaves' : 255,\n",
    "    'max_depth': 8,\n",
    "    'min_data_in_leaf': 23,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.41,\n",
    "    'silent': 1,\n",
    "    'random_state': 1337,\n",
    "    'verbose': 1,\n",
    "    'nthread': 9,\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'seed': 1337,\n",
    "    'colsample_bytree': 0.44,\n",
    "    'silent': 1,\n",
    "    'subsample': 0.82,\n",
    "    'eta': 0.02,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'max_depth': 7,\n",
    "    'min_child_weight': 22,\n",
    "    'nthread': 4,\n",
    "    'tree_method': 'hist',\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Columns dropped\n",
    "```python\n",
    "[100]\tvalid_0's binary_logloss: 0.211293\n",
    "[200]\tvalid_0's binary_logloss: 0.189018\n",
    "[300]\tvalid_0's binary_logloss: 0.185001\n",
    "[400]\tvalid_0's binary_logloss: 0.182913\n",
    "[500]\tvalid_0's binary_logloss: 0.181672\n",
    "[600]\tvalid_0's binary_logloss: 0.180901\n",
    "[700]\tvalid_0's binary_logloss: 0.180319\n",
    "[800]\tvalid_0's binary_logloss: 0.179623\n",
    "[900]\tvalid_0's binary_logloss: 0.179295\n",
    "[1000]\tvalid_0's binary_logloss: 0.179195\n",
    "[1100]\tvalid_0's binary_logloss: 0.179099\n",
    "[1200]\tvalid_0's binary_logloss: 0.179294\n",
    "Early stopping, best iteration is:\n",
    "[1074]\tvalid_0's binary_logloss: 0.179023\n",
    "Start predicting...\n",
    "Final score for fold 1 : 0.179031600541 \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lgb_foldrun(X_train, y_train, lgb_params, 'newNetworks_currentBest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running XGB model with parameters: {'objective': 'binary:logistic', 'silent': 1, 'min_child_weight': 22, 'max_depth': 7, 'nthread': 4, 'tree_method': 'hist', 'seed': 1337, 'eval_metric': 'logloss', 'eta': 0.02, 'subsample': 0.82, 'colsample_bytree': 0.44}\n",
      "Start training on fold: 1\n",
      "[0]\ttrain-logloss:0.678964\tvalid-logloss:0.678839\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 200 rounds.\n",
      "[100]\ttrain-logloss:0.247231\tvalid-logloss:0.24642\n",
      "[200]\ttrain-logloss:0.199212\tvalid-logloss:0.199961\n",
      "[300]\ttrain-logloss:0.187951\tvalid-logloss:0.190592\n",
      "[400]\ttrain-logloss:0.181526\tvalid-logloss:0.186831\n",
      "[500]\ttrain-logloss:0.176636\tvalid-logloss:0.184826\n",
      "[600]\ttrain-logloss:0.172202\tvalid-logloss:0.183296\n",
      "[700]\ttrain-logloss:0.168303\tvalid-logloss:0.182359\n",
      "[800]\ttrain-logloss:0.164828\tvalid-logloss:0.18164\n",
      "[900]\ttrain-logloss:0.161446\tvalid-logloss:0.18105\n",
      "[1000]\ttrain-logloss:0.158163\tvalid-logloss:0.180516\n",
      "[1100]\ttrain-logloss:0.154942\tvalid-logloss:0.180077\n",
      "[1200]\ttrain-logloss:0.152049\tvalid-logloss:0.179641\n",
      "[1300]\ttrain-logloss:0.149201\tvalid-logloss:0.179324\n",
      "[1400]\ttrain-logloss:0.146394\tvalid-logloss:0.179023\n",
      "[1500]\ttrain-logloss:0.143744\tvalid-logloss:0.17876\n",
      "[1600]\ttrain-logloss:0.141321\tvalid-logloss:0.17859\n",
      "[1700]\ttrain-logloss:0.138831\tvalid-logloss:0.17837\n",
      "[1800]\ttrain-logloss:0.136567\tvalid-logloss:0.178216\n",
      "[1900]\ttrain-logloss:0.134163\tvalid-logloss:0.178095\n",
      "[2000]\ttrain-logloss:0.131967\tvalid-logloss:0.177883\n",
      "[2100]\ttrain-logloss:0.129701\tvalid-logloss:0.177712\n",
      "[2200]\ttrain-logloss:0.127631\tvalid-logloss:0.177563\n",
      "[2300]\ttrain-logloss:0.125608\tvalid-logloss:0.177434\n",
      "[2400]\ttrain-logloss:0.123359\tvalid-logloss:0.17734\n",
      "[2500]\ttrain-logloss:0.121185\tvalid-logloss:0.177207\n",
      "[2600]\ttrain-logloss:0.119276\tvalid-logloss:0.17713\n",
      "[2700]\ttrain-logloss:0.117234\tvalid-logloss:0.177066\n",
      "[2800]\ttrain-logloss:0.115257\tvalid-logloss:0.176963\n",
      "[2900]\ttrain-logloss:0.113258\tvalid-logloss:0.176928\n",
      "[3000]\ttrain-logloss:0.111308\tvalid-logloss:0.176862\n",
      "[3100]\ttrain-logloss:0.109364\tvalid-logloss:0.176713\n",
      "[3200]\ttrain-logloss:0.107618\tvalid-logloss:0.17668\n",
      "[3300]\ttrain-logloss:0.105924\tvalid-logloss:0.176671\n",
      "[3400]\ttrain-logloss:0.104175\tvalid-logloss:0.176616\n",
      "[3500]\ttrain-logloss:0.102533\tvalid-logloss:0.176507\n",
      "[3600]\ttrain-logloss:0.100862\tvalid-logloss:0.176496\n",
      "[3700]\ttrain-logloss:0.099218\tvalid-logloss:0.176443\n",
      "[3800]\ttrain-logloss:0.097582\tvalid-logloss:0.176438\n",
      "[3900]\ttrain-logloss:0.096077\tvalid-logloss:0.176401\n",
      "[4000]\ttrain-logloss:0.094506\tvalid-logloss:0.176362\n",
      "[4100]\ttrain-logloss:0.093023\tvalid-logloss:0.176332\n",
      "[4200]\ttrain-logloss:0.091679\tvalid-logloss:0.176263\n",
      "[4300]\ttrain-logloss:0.090241\tvalid-logloss:0.17624\n",
      "[4400]\ttrain-logloss:0.088837\tvalid-logloss:0.176245\n",
      "[4500]\ttrain-logloss:0.087431\tvalid-logloss:0.176238\n",
      "[4600]\ttrain-logloss:0.08609\tvalid-logloss:0.176238\n",
      "[4700]\ttrain-logloss:0.084713\tvalid-logloss:0.176256\n",
      "[4800]\ttrain-logloss:0.083406\tvalid-logloss:0.176255\n",
      "Stopping. Best iteration:\n",
      "[4633]\ttrain-logloss:0.085616\tvalid-logloss:0.176208\n",
      "\n",
      "Start predicting...\n",
      "Final score for fold 1 : 0.176208417296 \n",
      " Time it took to train and predict on fold: 4924.378895282745 \n",
      "\n",
      "Start training on fold: 2\n",
      "[0]\ttrain-logloss:0.678904\tvalid-logloss:0.67908\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 200 rounds.\n",
      "[100]\ttrain-logloss:0.246535\tvalid-logloss:0.253018\n",
      "[200]\ttrain-logloss:0.198381\tvalid-logloss:0.2079\n",
      "[300]\ttrain-logloss:0.187055\tvalid-logloss:0.19885\n",
      "[400]\ttrain-logloss:0.180736\tvalid-logloss:0.195016\n",
      "[500]\ttrain-logloss:0.17577\tvalid-logloss:0.192886\n",
      "[600]\ttrain-logloss:0.171555\tvalid-logloss:0.191528\n",
      "[700]\ttrain-logloss:0.167506\tvalid-logloss:0.190401\n",
      "[800]\ttrain-logloss:0.163851\tvalid-logloss:0.189702\n",
      "[900]\ttrain-logloss:0.160629\tvalid-logloss:0.189144\n",
      "[1000]\ttrain-logloss:0.157397\tvalid-logloss:0.188689\n",
      "[1100]\ttrain-logloss:0.154473\tvalid-logloss:0.188292\n",
      "[1200]\ttrain-logloss:0.151689\tvalid-logloss:0.187874\n",
      "[1300]\ttrain-logloss:0.148855\tvalid-logloss:0.187602\n",
      "[1400]\ttrain-logloss:0.145878\tvalid-logloss:0.187399\n",
      "[1500]\ttrain-logloss:0.14325\tvalid-logloss:0.187083\n",
      "[1600]\ttrain-logloss:0.140763\tvalid-logloss:0.186791\n",
      "[1700]\ttrain-logloss:0.138336\tvalid-logloss:0.186588\n",
      "[1800]\ttrain-logloss:0.135893\tvalid-logloss:0.186366\n",
      "[1900]\ttrain-logloss:0.133688\tvalid-logloss:0.186265\n",
      "[2000]\ttrain-logloss:0.131539\tvalid-logloss:0.186066\n",
      "[2100]\ttrain-logloss:0.12928\tvalid-logloss:0.185922\n",
      "[2200]\ttrain-logloss:0.12704\tvalid-logloss:0.185733\n",
      "[2300]\ttrain-logloss:0.124856\tvalid-logloss:0.185646\n",
      "[2400]\ttrain-logloss:0.122805\tvalid-logloss:0.185524\n",
      "[2500]\ttrain-logloss:0.120783\tvalid-logloss:0.185423\n",
      "[2600]\ttrain-logloss:0.118733\tvalid-logloss:0.185335\n",
      "[2700]\ttrain-logloss:0.116773\tvalid-logloss:0.185256\n",
      "[2800]\ttrain-logloss:0.114903\tvalid-logloss:0.185175\n",
      "[2900]\ttrain-logloss:0.113058\tvalid-logloss:0.185105\n",
      "[3000]\ttrain-logloss:0.111279\tvalid-logloss:0.184989\n",
      "[3100]\ttrain-logloss:0.109596\tvalid-logloss:0.184959\n",
      "[3200]\ttrain-logloss:0.107748\tvalid-logloss:0.184904\n",
      "[3300]\ttrain-logloss:0.105858\tvalid-logloss:0.18485\n",
      "[3400]\ttrain-logloss:0.10421\tvalid-logloss:0.184805\n",
      "[3500]\ttrain-logloss:0.102637\tvalid-logloss:0.184769\n",
      "[3600]\ttrain-logloss:0.100976\tvalid-logloss:0.184739\n",
      "[3700]\ttrain-logloss:0.099393\tvalid-logloss:0.184691\n",
      "[3800]\ttrain-logloss:0.097864\tvalid-logloss:0.184563\n",
      "[3900]\ttrain-logloss:0.096268\tvalid-logloss:0.184515\n",
      "[4000]\ttrain-logloss:0.094782\tvalid-logloss:0.184546\n",
      "[4100]\ttrain-logloss:0.093276\tvalid-logloss:0.184572\n",
      "Stopping. Best iteration:\n",
      "[3903]\ttrain-logloss:0.096217\tvalid-logloss:0.184509\n",
      "\n",
      "Start predicting...\n",
      "Final score for fold 2 : 0.184509089613 \n",
      " Time it took to train and predict on fold: 4286.782591342926 \n",
      "\n",
      "Start training on fold: 3\n",
      "[0]\ttrain-logloss:0.678941\tvalid-logloss:0.678878\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 200 rounds.\n",
      "[100]\ttrain-logloss:0.24701\tvalid-logloss:0.247643\n",
      "[200]\ttrain-logloss:0.198979\tvalid-logloss:0.202019\n",
      "[300]\ttrain-logloss:0.187636\tvalid-logloss:0.19325\n",
      "[400]\ttrain-logloss:0.181066\tvalid-logloss:0.189721\n",
      "[500]\ttrain-logloss:0.176226\tvalid-logloss:0.187993\n",
      "[600]\ttrain-logloss:0.172045\tvalid-logloss:0.186736\n",
      "[700]\ttrain-logloss:0.167976\tvalid-logloss:0.185691\n",
      "[800]\ttrain-logloss:0.164362\tvalid-logloss:0.184826\n",
      "[900]\ttrain-logloss:0.160994\tvalid-logloss:0.184221\n",
      "[1000]\ttrain-logloss:0.157784\tvalid-logloss:0.183634\n",
      "[1100]\ttrain-logloss:0.154833\tvalid-logloss:0.183275\n",
      "[1200]\ttrain-logloss:0.151885\tvalid-logloss:0.182948\n",
      "[1300]\ttrain-logloss:0.148999\tvalid-logloss:0.182593\n",
      "[1400]\ttrain-logloss:0.146179\tvalid-logloss:0.182288\n",
      "[1500]\ttrain-logloss:0.143734\tvalid-logloss:0.182053\n",
      "[1600]\ttrain-logloss:0.141161\tvalid-logloss:0.181818\n",
      "[1700]\ttrain-logloss:0.138736\tvalid-logloss:0.181566\n",
      "[1800]\ttrain-logloss:0.136336\tvalid-logloss:0.181384\n",
      "[1900]\ttrain-logloss:0.134064\tvalid-logloss:0.181241\n",
      "[2000]\ttrain-logloss:0.131873\tvalid-logloss:0.181084\n",
      "[2100]\ttrain-logloss:0.129668\tvalid-logloss:0.1809\n",
      "[2200]\ttrain-logloss:0.127522\tvalid-logloss:0.180764\n",
      "[2300]\ttrain-logloss:0.12527\tvalid-logloss:0.180643\n",
      "[2400]\ttrain-logloss:0.123334\tvalid-logloss:0.180497\n",
      "[2500]\ttrain-logloss:0.121339\tvalid-logloss:0.180367\n",
      "[2600]\ttrain-logloss:0.11925\tvalid-logloss:0.180249\n",
      "[2700]\ttrain-logloss:0.11733\tvalid-logloss:0.18013\n",
      "[2800]\ttrain-logloss:0.115357\tvalid-logloss:0.180003\n",
      "[2900]\ttrain-logloss:0.11349\tvalid-logloss:0.17995\n",
      "[3000]\ttrain-logloss:0.111753\tvalid-logloss:0.179841\n",
      "[3100]\ttrain-logloss:0.109927\tvalid-logloss:0.179725\n",
      "[3200]\ttrain-logloss:0.108224\tvalid-logloss:0.179696\n",
      "[3300]\ttrain-logloss:0.106482\tvalid-logloss:0.179563\n",
      "[3400]\ttrain-logloss:0.104715\tvalid-logloss:0.179603\n",
      "[3500]\ttrain-logloss:0.103101\tvalid-logloss:0.179617\n",
      "Stopping. Best iteration:\n",
      "[3336]\ttrain-logloss:0.10588\tvalid-logloss:0.179538\n",
      "\n",
      "Start predicting...\n",
      "Final score for fold 3 : 0.179538227159 \n",
      " Time it took to train and predict on fold: 3676.492738008499 \n",
      "\n",
      "Start training on fold: 4\n",
      "[0]\ttrain-logloss:0.678908\tvalid-logloss:0.67868\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will train until valid-logloss hasn't improved in 200 rounds.\n",
      "[100]\ttrain-logloss:0.247733\tvalid-logloss:0.245394\n",
      "[200]\ttrain-logloss:0.199046\tvalid-logloss:0.199227\n",
      "[300]\ttrain-logloss:0.187931\tvalid-logloss:0.190633\n",
      "[400]\ttrain-logloss:0.181866\tvalid-logloss:0.187264\n",
      "[500]\ttrain-logloss:0.176738\tvalid-logloss:0.185238\n",
      "[600]\ttrain-logloss:0.172063\tvalid-logloss:0.183854\n",
      "[700]\ttrain-logloss:0.168085\tvalid-logloss:0.182902\n",
      "[800]\ttrain-logloss:0.164532\tvalid-logloss:0.182184\n",
      "[900]\ttrain-logloss:0.161251\tvalid-logloss:0.181666\n",
      "[1000]\ttrain-logloss:0.157922\tvalid-logloss:0.181238\n",
      "[1100]\ttrain-logloss:0.154843\tvalid-logloss:0.180786\n",
      "[1200]\ttrain-logloss:0.151944\tvalid-logloss:0.180411\n",
      "[1300]\ttrain-logloss:0.149086\tvalid-logloss:0.180078\n",
      "[1400]\ttrain-logloss:0.146343\tvalid-logloss:0.179753\n",
      "[1500]\ttrain-logloss:0.143759\tvalid-logloss:0.179536\n",
      "[1600]\ttrain-logloss:0.141283\tvalid-logloss:0.17939\n",
      "[1700]\ttrain-logloss:0.138752\tvalid-logloss:0.179129\n",
      "[1800]\ttrain-logloss:0.13643\tvalid-logloss:0.178959\n",
      "[1900]\ttrain-logloss:0.134043\tvalid-logloss:0.178752\n",
      "[2000]\ttrain-logloss:0.131669\tvalid-logloss:0.178629\n",
      "[2100]\ttrain-logloss:0.129378\tvalid-logloss:0.178474\n",
      "[2200]\ttrain-logloss:0.127231\tvalid-logloss:0.178329\n",
      "[2300]\ttrain-logloss:0.125205\tvalid-logloss:0.178238\n",
      "[2400]\ttrain-logloss:0.123194\tvalid-logloss:0.178091\n",
      "[2500]\ttrain-logloss:0.121262\tvalid-logloss:0.178018\n",
      "[2600]\ttrain-logloss:0.119244\tvalid-logloss:0.177887\n",
      "[2700]\ttrain-logloss:0.117217\tvalid-logloss:0.177729\n",
      "[2800]\ttrain-logloss:0.115341\tvalid-logloss:0.17768\n",
      "[2900]\ttrain-logloss:0.113429\tvalid-logloss:0.177626\n",
      "[3000]\ttrain-logloss:0.111511\tvalid-logloss:0.177616\n",
      "[3100]\ttrain-logloss:0.109636\tvalid-logloss:0.177532\n",
      "[3200]\ttrain-logloss:0.107842\tvalid-logloss:0.177421\n",
      "[3300]\ttrain-logloss:0.106165\tvalid-logloss:0.177364\n",
      "[3400]\ttrain-logloss:0.104458\tvalid-logloss:0.177282\n",
      "[3500]\ttrain-logloss:0.102796\tvalid-logloss:0.177239\n",
      "[3600]\ttrain-logloss:0.101137\tvalid-logloss:0.177252\n",
      "[3700]\ttrain-logloss:0.099527\tvalid-logloss:0.177193\n",
      "[3800]\ttrain-logloss:0.097917\tvalid-logloss:0.177234\n",
      "[3900]\ttrain-logloss:0.096398\tvalid-logloss:0.177216\n",
      "Stopping. Best iteration:\n",
      "[3751]\ttrain-logloss:0.098719\tvalid-logloss:0.177191\n",
      "\n",
      "Start predicting...\n",
      "Final score for fold 4 : 0.177191338459 \n",
      " Time it took to train and predict on fold: 3898.8988728523254 \n",
      "\n",
      "Start training on fold: 5\n",
      "[0]\ttrain-logloss:0.678886\tvalid-logloss:0.678908\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 200 rounds.\n",
      "[100]\ttrain-logloss:0.24705\tvalid-logloss:0.25111\n",
      "[200]\ttrain-logloss:0.198553\tvalid-logloss:0.205608\n",
      "[300]\ttrain-logloss:0.187327\tvalid-logloss:0.196828\n",
      "[400]\ttrain-logloss:0.180983\tvalid-logloss:0.193208\n",
      "[500]\ttrain-logloss:0.176008\tvalid-logloss:0.191165\n",
      "[600]\ttrain-logloss:0.171424\tvalid-logloss:0.189828\n",
      "[700]\ttrain-logloss:0.167294\tvalid-logloss:0.188824\n",
      "[800]\ttrain-logloss:0.163674\tvalid-logloss:0.18799\n",
      "[900]\ttrain-logloss:0.160465\tvalid-logloss:0.187374\n",
      "[1000]\ttrain-logloss:0.157311\tvalid-logloss:0.186954\n",
      "[1100]\ttrain-logloss:0.154347\tvalid-logloss:0.186462\n",
      "[1200]\ttrain-logloss:0.151581\tvalid-logloss:0.186105\n",
      "[1300]\ttrain-logloss:0.148864\tvalid-logloss:0.185764\n",
      "[1400]\ttrain-logloss:0.146221\tvalid-logloss:0.18544\n",
      "[1500]\ttrain-logloss:0.143492\tvalid-logloss:0.18521\n",
      "[1600]\ttrain-logloss:0.140756\tvalid-logloss:0.184957\n",
      "[1700]\ttrain-logloss:0.138272\tvalid-logloss:0.184735\n",
      "[1800]\ttrain-logloss:0.135954\tvalid-logloss:0.184508\n",
      "[1900]\ttrain-logloss:0.133639\tvalid-logloss:0.184334\n",
      "[2000]\ttrain-logloss:0.131343\tvalid-logloss:0.184175\n",
      "[2100]\ttrain-logloss:0.129087\tvalid-logloss:0.184092\n",
      "[2200]\ttrain-logloss:0.126948\tvalid-logloss:0.183873\n",
      "[2300]\ttrain-logloss:0.124763\tvalid-logloss:0.183745\n",
      "[2400]\ttrain-logloss:0.122735\tvalid-logloss:0.183701\n",
      "[2500]\ttrain-logloss:0.120736\tvalid-logloss:0.183604\n",
      "[2600]\ttrain-logloss:0.118767\tvalid-logloss:0.183556\n",
      "[2700]\ttrain-logloss:0.116871\tvalid-logloss:0.183475\n",
      "[2800]\ttrain-logloss:0.115028\tvalid-logloss:0.183428\n",
      "[2900]\ttrain-logloss:0.113159\tvalid-logloss:0.183449\n",
      "[3000]\ttrain-logloss:0.111358\tvalid-logloss:0.183405\n",
      "[3100]\ttrain-logloss:0.10949\tvalid-logloss:0.183301\n",
      "[3200]\ttrain-logloss:0.107701\tvalid-logloss:0.183211\n",
      "[3300]\ttrain-logloss:0.105953\tvalid-logloss:0.183138\n",
      "[3400]\ttrain-logloss:0.104233\tvalid-logloss:0.183135\n",
      "[3500]\ttrain-logloss:0.102671\tvalid-logloss:0.18308\n",
      "[3600]\ttrain-logloss:0.10113\tvalid-logloss:0.183058\n",
      "[3700]\ttrain-logloss:0.099499\tvalid-logloss:0.183059\n",
      "[3800]\ttrain-logloss:0.097852\tvalid-logloss:0.18305\n",
      "Stopping. Best iteration:\n",
      "[3626]\ttrain-logloss:0.100663\tvalid-logloss:0.183027\n",
      "\n",
      "Start predicting...\n",
      "Final score for fold 5 : 0.183026682547 \n",
      " Time it took to train and predict on fold: 3974.7133119106293 \n",
      "\n",
      "Start training on fold: 6\n",
      "[0]\ttrain-logloss:0.678889\tvalid-logloss:0.67892\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 200 rounds.\n",
      "[100]\ttrain-logloss:0.24718\tvalid-logloss:0.249669\n",
      "[200]\ttrain-logloss:0.198645\tvalid-logloss:0.203578\n",
      "[300]\ttrain-logloss:0.187394\tvalid-logloss:0.194382\n",
      "[400]\ttrain-logloss:0.181239\tvalid-logloss:0.190728\n",
      "[500]\ttrain-logloss:0.176335\tvalid-logloss:0.188559\n",
      "[600]\ttrain-logloss:0.171519\tvalid-logloss:0.187009\n",
      "[700]\ttrain-logloss:0.167433\tvalid-logloss:0.185825\n",
      "[800]\ttrain-logloss:0.163694\tvalid-logloss:0.185056\n",
      "[900]\ttrain-logloss:0.160349\tvalid-logloss:0.184474\n",
      "[1000]\ttrain-logloss:0.157131\tvalid-logloss:0.183988\n",
      "[1100]\ttrain-logloss:0.154321\tvalid-logloss:0.183485\n",
      "[1200]\ttrain-logloss:0.151497\tvalid-logloss:0.183226\n",
      "[1300]\ttrain-logloss:0.148715\tvalid-logloss:0.182857\n",
      "[1400]\ttrain-logloss:0.146061\tvalid-logloss:0.182531\n",
      "[1500]\ttrain-logloss:0.143509\tvalid-logloss:0.182303\n",
      "[1600]\ttrain-logloss:0.140998\tvalid-logloss:0.182113\n",
      "[1700]\ttrain-logloss:0.138518\tvalid-logloss:0.181879\n",
      "[1800]\ttrain-logloss:0.136093\tvalid-logloss:0.181722\n",
      "[1900]\ttrain-logloss:0.133812\tvalid-logloss:0.181499\n",
      "[2000]\ttrain-logloss:0.131461\tvalid-logloss:0.181349\n",
      "[2100]\ttrain-logloss:0.129402\tvalid-logloss:0.181234\n",
      "[2200]\ttrain-logloss:0.127192\tvalid-logloss:0.181074\n",
      "[2300]\ttrain-logloss:0.125086\tvalid-logloss:0.180984\n",
      "[2400]\ttrain-logloss:0.123001\tvalid-logloss:0.180828\n",
      "[2500]\ttrain-logloss:0.121059\tvalid-logloss:0.180711\n",
      "[2600]\ttrain-logloss:0.118979\tvalid-logloss:0.180631\n",
      "[2700]\ttrain-logloss:0.116982\tvalid-logloss:0.180493\n",
      "[2800]\ttrain-logloss:0.115072\tvalid-logloss:0.180365\n",
      "[2900]\ttrain-logloss:0.113203\tvalid-logloss:0.180337\n",
      "[3000]\ttrain-logloss:0.111357\tvalid-logloss:0.180275\n",
      "[3100]\ttrain-logloss:0.109645\tvalid-logloss:0.1802\n",
      "[3200]\ttrain-logloss:0.107878\tvalid-logloss:0.180112\n",
      "[3300]\ttrain-logloss:0.106153\tvalid-logloss:0.180103\n",
      "[3400]\ttrain-logloss:0.10446\tvalid-logloss:0.180092\n",
      "[3500]\ttrain-logloss:0.102833\tvalid-logloss:0.180047\n",
      "[3600]\ttrain-logloss:0.101138\tvalid-logloss:0.180025\n",
      "[3700]\ttrain-logloss:0.099525\tvalid-logloss:0.179945\n",
      "[3800]\ttrain-logloss:0.097939\tvalid-logloss:0.179969\n",
      "[3900]\ttrain-logloss:0.096391\tvalid-logloss:0.179986\n",
      "Stopping. Best iteration:\n",
      "[3717]\ttrain-logloss:0.099247\tvalid-logloss:0.179933\n",
      "\n",
      "Start predicting...\n",
      "Final score for fold 6 : 0.179933312262 \n",
      " Time it took to train and predict on fold: 4002.79576420784 \n",
      "\n",
      "Start training on fold: 7\n",
      "[0]\ttrain-logloss:0.67887\tvalid-logloss:0.679062\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 200 rounds.\n",
      "[100]\ttrain-logloss:0.246919\tvalid-logloss:0.252766\n",
      "[200]\ttrain-logloss:0.198434\tvalid-logloss:0.206192\n",
      "[300]\ttrain-logloss:0.187096\tvalid-logloss:0.196634\n",
      "[400]\ttrain-logloss:0.180941\tvalid-logloss:0.192812\n",
      "[500]\ttrain-logloss:0.176029\tvalid-logloss:0.1907\n",
      "[600]\ttrain-logloss:0.171432\tvalid-logloss:0.189167\n",
      "[700]\ttrain-logloss:0.167308\tvalid-logloss:0.188016\n",
      "[800]\ttrain-logloss:0.163496\tvalid-logloss:0.187189\n",
      "[900]\ttrain-logloss:0.160057\tvalid-logloss:0.186502\n",
      "[1000]\ttrain-logloss:0.156939\tvalid-logloss:0.185944\n",
      "[1100]\ttrain-logloss:0.153976\tvalid-logloss:0.185447\n",
      "[1200]\ttrain-logloss:0.151068\tvalid-logloss:0.185115\n",
      "[1300]\ttrain-logloss:0.148383\tvalid-logloss:0.184874\n",
      "[1400]\ttrain-logloss:0.145698\tvalid-logloss:0.184521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1500]\ttrain-logloss:0.143123\tvalid-logloss:0.184202\n",
      "[1600]\ttrain-logloss:0.140708\tvalid-logloss:0.183922\n",
      "[1700]\ttrain-logloss:0.138316\tvalid-logloss:0.183682\n",
      "[1800]\ttrain-logloss:0.135892\tvalid-logloss:0.183444\n",
      "[1900]\ttrain-logloss:0.133547\tvalid-logloss:0.183341\n",
      "[2000]\ttrain-logloss:0.131303\tvalid-logloss:0.183097\n",
      "[2100]\ttrain-logloss:0.129127\tvalid-logloss:0.182916\n",
      "[2200]\ttrain-logloss:0.126807\tvalid-logloss:0.182778\n",
      "[2300]\ttrain-logloss:0.124679\tvalid-logloss:0.182599\n",
      "[2400]\ttrain-logloss:0.12263\tvalid-logloss:0.18243\n",
      "[2500]\ttrain-logloss:0.120572\tvalid-logloss:0.182215\n",
      "[2600]\ttrain-logloss:0.118455\tvalid-logloss:0.182041\n",
      "[2700]\ttrain-logloss:0.116576\tvalid-logloss:0.181912\n",
      "[2800]\ttrain-logloss:0.114806\tvalid-logloss:0.1818\n",
      "[2900]\ttrain-logloss:0.113004\tvalid-logloss:0.181657\n",
      "[3000]\ttrain-logloss:0.111096\tvalid-logloss:0.181567\n",
      "[3100]\ttrain-logloss:0.109281\tvalid-logloss:0.181474\n",
      "[3200]\ttrain-logloss:0.107386\tvalid-logloss:0.181412\n",
      "[3300]\ttrain-logloss:0.105663\tvalid-logloss:0.181331\n",
      "[3400]\ttrain-logloss:0.104008\tvalid-logloss:0.181213\n",
      "[3500]\ttrain-logloss:0.102377\tvalid-logloss:0.181133\n",
      "[3600]\ttrain-logloss:0.100754\tvalid-logloss:0.181069\n",
      "[3700]\ttrain-logloss:0.099184\tvalid-logloss:0.180981\n",
      "[3800]\ttrain-logloss:0.097558\tvalid-logloss:0.180962\n",
      "[3900]\ttrain-logloss:0.096079\tvalid-logloss:0.180836\n",
      "[4000]\ttrain-logloss:0.094635\tvalid-logloss:0.180797\n",
      "[4100]\ttrain-logloss:0.093196\tvalid-logloss:0.180768\n",
      "[4200]\ttrain-logloss:0.091681\tvalid-logloss:0.180749\n",
      "[4300]\ttrain-logloss:0.09024\tvalid-logloss:0.180744\n",
      "[4400]\ttrain-logloss:0.088841\tvalid-logloss:0.180672\n",
      "[4500]\ttrain-logloss:0.087453\tvalid-logloss:0.180615\n",
      "[4600]\ttrain-logloss:0.086073\tvalid-logloss:0.180561\n",
      "[4700]\ttrain-logloss:0.084846\tvalid-logloss:0.180548\n",
      "[4800]\ttrain-logloss:0.083542\tvalid-logloss:0.180535\n",
      "[4900]\ttrain-logloss:0.082247\tvalid-logloss:0.18052\n",
      "[5000]\ttrain-logloss:0.080985\tvalid-logloss:0.180492\n",
      "[5100]\ttrain-logloss:0.079766\tvalid-logloss:0.180458\n",
      "[5200]\ttrain-logloss:0.078499\tvalid-logloss:0.180443\n",
      "[5300]\ttrain-logloss:0.077206\tvalid-logloss:0.180446\n",
      "[5400]\ttrain-logloss:0.076019\tvalid-logloss:0.180424\n",
      "Stopping. Best iteration:\n",
      "[5255]\ttrain-logloss:0.07781\tvalid-logloss:0.1804\n",
      "\n",
      "Start predicting...\n",
      "Final score for fold 7 : 0.180399663648 \n",
      " Time it took to train and predict on fold: 5791.343701601028 \n",
      "\n",
      "Start training on fold: 8\n",
      "[0]\ttrain-logloss:0.678911\tvalid-logloss:0.678923\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 200 rounds.\n",
      "[100]\ttrain-logloss:0.247222\tvalid-logloss:0.248694\n",
      "[200]\ttrain-logloss:0.199215\tvalid-logloss:0.202297\n",
      "[300]\ttrain-logloss:0.187938\tvalid-logloss:0.193039\n",
      "[400]\ttrain-logloss:0.181216\tvalid-logloss:0.189157\n",
      "[500]\ttrain-logloss:0.176168\tvalid-logloss:0.187078\n",
      "[600]\ttrain-logloss:0.172003\tvalid-logloss:0.185764\n",
      "[700]\ttrain-logloss:0.167931\tvalid-logloss:0.184734\n",
      "[800]\ttrain-logloss:0.164124\tvalid-logloss:0.183949\n",
      "[900]\ttrain-logloss:0.16073\tvalid-logloss:0.183375\n",
      "[1000]\ttrain-logloss:0.157514\tvalid-logloss:0.182915\n",
      "[1100]\ttrain-logloss:0.154463\tvalid-logloss:0.182408\n",
      "[1200]\ttrain-logloss:0.151677\tvalid-logloss:0.182024\n",
      "[1300]\ttrain-logloss:0.149012\tvalid-logloss:0.181598\n",
      "[1400]\ttrain-logloss:0.146334\tvalid-logloss:0.18137\n",
      "[1500]\ttrain-logloss:0.14379\tvalid-logloss:0.181095\n",
      "[1600]\ttrain-logloss:0.141411\tvalid-logloss:0.180868\n",
      "[1700]\ttrain-logloss:0.139022\tvalid-logloss:0.180589\n",
      "[1800]\ttrain-logloss:0.136505\tvalid-logloss:0.180387\n",
      "[1900]\ttrain-logloss:0.133926\tvalid-logloss:0.180206\n",
      "[2000]\ttrain-logloss:0.131745\tvalid-logloss:0.180026\n",
      "[2100]\ttrain-logloss:0.129501\tvalid-logloss:0.179891\n",
      "[2200]\ttrain-logloss:0.127348\tvalid-logloss:0.179782\n",
      "[2300]\ttrain-logloss:0.125287\tvalid-logloss:0.179599\n",
      "[2400]\ttrain-logloss:0.123192\tvalid-logloss:0.179501\n",
      "[2500]\ttrain-logloss:0.121216\tvalid-logloss:0.179397\n",
      "[2600]\ttrain-logloss:0.119259\tvalid-logloss:0.17937\n",
      "[2700]\ttrain-logloss:0.117333\tvalid-logloss:0.17925\n",
      "[2800]\ttrain-logloss:0.115337\tvalid-logloss:0.179173\n",
      "[2900]\ttrain-logloss:0.113491\tvalid-logloss:0.179106\n",
      "[3000]\ttrain-logloss:0.111675\tvalid-logloss:0.178988\n",
      "[3100]\ttrain-logloss:0.109933\tvalid-logloss:0.178802\n",
      "[3200]\ttrain-logloss:0.108206\tvalid-logloss:0.17873\n",
      "[3300]\ttrain-logloss:0.106547\tvalid-logloss:0.178648\n",
      "[3400]\ttrain-logloss:0.104795\tvalid-logloss:0.17862\n",
      "[3500]\ttrain-logloss:0.1031\tvalid-logloss:0.17854\n",
      "[3600]\ttrain-logloss:0.101524\tvalid-logloss:0.178485\n",
      "[3700]\ttrain-logloss:0.099979\tvalid-logloss:0.178468\n",
      "[3800]\ttrain-logloss:0.098365\tvalid-logloss:0.178466\n",
      "[3900]\ttrain-logloss:0.096853\tvalid-logloss:0.178468\n",
      "Stopping. Best iteration:\n",
      "[3761]\ttrain-logloss:0.098985\tvalid-logloss:0.17845\n",
      "\n",
      "Start predicting...\n",
      "Final score for fold 8 : 0.178450094325 \n",
      " Time it took to train and predict on fold: 4324.948215723038 \n",
      "\n",
      "Start training on fold: 9\n",
      "[0]\ttrain-logloss:0.678909\tvalid-logloss:0.679073\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 200 rounds.\n",
      "[100]\ttrain-logloss:0.246871\tvalid-logloss:0.250991\n",
      "[200]\ttrain-logloss:0.198879\tvalid-logloss:0.205105\n",
      "[300]\ttrain-logloss:0.187605\tvalid-logloss:0.195919\n",
      "[400]\ttrain-logloss:0.181001\tvalid-logloss:0.19217\n",
      "[500]\ttrain-logloss:0.175979\tvalid-logloss:0.190094\n",
      "[600]\ttrain-logloss:0.171569\tvalid-logloss:0.188748\n",
      "[700]\ttrain-logloss:0.167303\tvalid-logloss:0.187695\n",
      "[800]\ttrain-logloss:0.163624\tvalid-logloss:0.186942\n",
      "[900]\ttrain-logloss:0.160343\tvalid-logloss:0.186336\n",
      "[1000]\ttrain-logloss:0.15712\tvalid-logloss:0.185862\n",
      "[1100]\ttrain-logloss:0.154028\tvalid-logloss:0.185372\n",
      "[1200]\ttrain-logloss:0.151251\tvalid-logloss:0.185047\n",
      "[1300]\ttrain-logloss:0.148573\tvalid-logloss:0.184749\n",
      "[1400]\ttrain-logloss:0.146041\tvalid-logloss:0.184468\n",
      "[1500]\ttrain-logloss:0.143439\tvalid-logloss:0.184262\n",
      "[1600]\ttrain-logloss:0.140901\tvalid-logloss:0.184001\n",
      "[1700]\ttrain-logloss:0.138435\tvalid-logloss:0.18376\n",
      "[1800]\ttrain-logloss:0.136033\tvalid-logloss:0.183586\n",
      "[1900]\ttrain-logloss:0.133714\tvalid-logloss:0.183308\n",
      "[2000]\ttrain-logloss:0.131346\tvalid-logloss:0.18316\n",
      "[2100]\ttrain-logloss:0.129186\tvalid-logloss:0.183014\n",
      "[2200]\ttrain-logloss:0.127104\tvalid-logloss:0.182861\n",
      "[2300]\ttrain-logloss:0.125103\tvalid-logloss:0.182763\n",
      "[2400]\ttrain-logloss:0.123143\tvalid-logloss:0.18265\n",
      "[2500]\ttrain-logloss:0.121045\tvalid-logloss:0.18257\n",
      "[2600]\ttrain-logloss:0.118988\tvalid-logloss:0.18242\n",
      "[2700]\ttrain-logloss:0.117019\tvalid-logloss:0.182363\n",
      "[2800]\ttrain-logloss:0.11504\tvalid-logloss:0.182204\n",
      "[2900]\ttrain-logloss:0.113142\tvalid-logloss:0.182129\n",
      "[3000]\ttrain-logloss:0.111446\tvalid-logloss:0.182016\n",
      "[3100]\ttrain-logloss:0.109645\tvalid-logloss:0.181918\n",
      "[3200]\ttrain-logloss:0.10787\tvalid-logloss:0.18187\n",
      "[3300]\ttrain-logloss:0.10612\tvalid-logloss:0.181794\n",
      "[3400]\ttrain-logloss:0.104448\tvalid-logloss:0.181701\n",
      "[3500]\ttrain-logloss:0.102812\tvalid-logloss:0.181619\n",
      "[3600]\ttrain-logloss:0.101222\tvalid-logloss:0.181568\n",
      "[3700]\ttrain-logloss:0.099591\tvalid-logloss:0.181508\n",
      "[3800]\ttrain-logloss:0.097924\tvalid-logloss:0.181489\n",
      "[3900]\ttrain-logloss:0.096373\tvalid-logloss:0.181456\n",
      "[4000]\ttrain-logloss:0.094781\tvalid-logloss:0.181412\n",
      "[4100]\ttrain-logloss:0.093313\tvalid-logloss:0.181341\n",
      "[4200]\ttrain-logloss:0.091852\tvalid-logloss:0.181322\n",
      "[4300]\ttrain-logloss:0.090475\tvalid-logloss:0.181302\n",
      "[4400]\ttrain-logloss:0.089095\tvalid-logloss:0.18127\n",
      "[4500]\ttrain-logloss:0.087813\tvalid-logloss:0.181203\n",
      "[4600]\ttrain-logloss:0.086384\tvalid-logloss:0.181252\n",
      "[4700]\ttrain-logloss:0.085058\tvalid-logloss:0.181264\n",
      "Stopping. Best iteration:\n",
      "[4540]\ttrain-logloss:0.087296\tvalid-logloss:0.181179\n",
      "\n",
      "Start predicting...\n",
      "Final score for fold 9 : 0.181179445011 \n",
      " Time it took to train and predict on fold: 5801.241550922394 \n",
      "\n",
      "Start training on fold: 10\n",
      "[0]\ttrain-logloss:0.678903\tvalid-logloss:0.679126\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 200 rounds.\n",
      "[100]\ttrain-logloss:0.246704\tvalid-logloss:0.252464\n",
      "[200]\ttrain-logloss:0.198785\tvalid-logloss:0.206183\n",
      "[300]\ttrain-logloss:0.187664\tvalid-logloss:0.196643\n",
      "[400]\ttrain-logloss:0.18109\tvalid-logloss:0.192499\n",
      "[500]\ttrain-logloss:0.176078\tvalid-logloss:0.190262\n",
      "[600]\ttrain-logloss:0.17173\tvalid-logloss:0.188773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[700]\ttrain-logloss:0.167544\tvalid-logloss:0.187784\n",
      "[800]\ttrain-logloss:0.163837\tvalid-logloss:0.187053\n",
      "[900]\ttrain-logloss:0.160354\tvalid-logloss:0.186463\n",
      "[1000]\ttrain-logloss:0.157102\tvalid-logloss:0.186053\n",
      "[1100]\ttrain-logloss:0.153885\tvalid-logloss:0.185496\n",
      "[1200]\ttrain-logloss:0.151078\tvalid-logloss:0.185165\n",
      "[1300]\ttrain-logloss:0.148267\tvalid-logloss:0.184756\n",
      "[1400]\ttrain-logloss:0.145587\tvalid-logloss:0.184492\n",
      "[1500]\ttrain-logloss:0.142947\tvalid-logloss:0.184224\n",
      "[1600]\ttrain-logloss:0.140379\tvalid-logloss:0.184011\n",
      "[1700]\ttrain-logloss:0.138003\tvalid-logloss:0.183786\n",
      "[1800]\ttrain-logloss:0.135555\tvalid-logloss:0.183619\n",
      "[1900]\ttrain-logloss:0.13323\tvalid-logloss:0.183459\n",
      "[2000]\ttrain-logloss:0.131104\tvalid-logloss:0.183298\n",
      "[2100]\ttrain-logloss:0.128833\tvalid-logloss:0.183199\n",
      "[2200]\ttrain-logloss:0.126703\tvalid-logloss:0.183015\n",
      "[2300]\ttrain-logloss:0.124629\tvalid-logloss:0.182932\n",
      "[2400]\ttrain-logloss:0.122613\tvalid-logloss:0.182857\n",
      "[2500]\ttrain-logloss:0.120618\tvalid-logloss:0.18273\n",
      "[2600]\ttrain-logloss:0.118771\tvalid-logloss:0.182659\n",
      "[2700]\ttrain-logloss:0.116782\tvalid-logloss:0.182568\n",
      "[2800]\ttrain-logloss:0.114866\tvalid-logloss:0.18251\n",
      "[2900]\ttrain-logloss:0.11296\tvalid-logloss:0.182416\n",
      "[3000]\ttrain-logloss:0.11115\tvalid-logloss:0.182354\n",
      "[3100]\ttrain-logloss:0.109349\tvalid-logloss:0.182309\n",
      "[3200]\ttrain-logloss:0.107487\tvalid-logloss:0.182297\n",
      "[3300]\ttrain-logloss:0.105775\tvalid-logloss:0.182223\n",
      "[3400]\ttrain-logloss:0.104126\tvalid-logloss:0.182148\n",
      "[3500]\ttrain-logloss:0.102368\tvalid-logloss:0.182097\n",
      "[3600]\ttrain-logloss:0.100794\tvalid-logloss:0.182041\n",
      "[3700]\ttrain-logloss:0.099294\tvalid-logloss:0.181997\n",
      "[3800]\ttrain-logloss:0.097761\tvalid-logloss:0.18194\n",
      "[3900]\ttrain-logloss:0.096191\tvalid-logloss:0.181879\n",
      "[4000]\ttrain-logloss:0.0946\tvalid-logloss:0.181842\n",
      "[4100]\ttrain-logloss:0.093141\tvalid-logloss:0.181837\n",
      "[4200]\ttrain-logloss:0.091705\tvalid-logloss:0.181819\n",
      "[4300]\ttrain-logloss:0.090228\tvalid-logloss:0.181797\n",
      "[4400]\ttrain-logloss:0.088808\tvalid-logloss:0.181747\n",
      "[4500]\ttrain-logloss:0.08747\tvalid-logloss:0.181788\n",
      "Stopping. Best iteration:\n",
      "[4384]\ttrain-logloss:0.089063\tvalid-logloss:0.181743\n",
      "\n",
      "Start predicting...\n",
      "Final score for fold 10 : 0.181743456447 \n",
      " Time it took to train and predict on fold: 4221.890212059021 \n",
      "\n",
      "Mean logloss for model in 10-folds SKF: 0.180217972677\n"
     ]
    }
   ],
   "source": [
    "xgb_foldrun(X_train, y_train, xgb_params, 'newNetworks_currentBest')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "feats_src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/data/features/uncleaned/'\n",
    "\n",
    "xgb_feats = pd.read_csv(feats_src + '/the_1owl/owl_train.csv')\n",
    "y_train = xgb_feats[['is_duplicate']]\n",
    "\n",
    "X_train2 = pd.read_pickle('Xtrain_currentBest_400feats.pkl')\n",
    "X_test2 = pd.read_pickle('Xtest_currentBest_400feats.pkl')\n",
    "\n",
    "oof_test = lgb_foldrun_test(X_train2, y_train, X_test2, lgb_params, 'CurrentBestGRU_400feats')\n",
    "oof_test.to_pickle('OOF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gbm = xgb.Booster(model_file = 'saved_models/XGB/XGB_10SKF_FredFeatsGRU_loss0.17917_fold1.txt')\n",
    "dtrain = xgb.DMatrix(X_train, label = y_train)\n",
    "\n",
    "mapper = {'f{0}'.format(i): v for i, v in enumerate(dtrain.feature_names)}\n",
    "importance = {mapper[k]: v for k, v in gbm.get_fscore().items()}\n",
    "importance = sorted(importance.items(), key=lambda x:x[1], reverse=True)[:20]\n",
    "\n",
    "df_importance = pd.DataFrame(importance, columns=['feature', 'fscore'])\n",
    "df_importance['fscore'] = df_importance['fscore'] / df_importance['fscore'].sum()\n",
    "\n",
    "plt.figure()\n",
    "df_importance.plot()\n",
    "df_importance.plot(kind='barh', x='feature', y='fscore', legend=False, figsize=(10, 18))\n",
    "plt.title('XGBoost Feature Importance')\n",
    "plt.xlabel('relative importance')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
