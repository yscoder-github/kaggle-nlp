{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import difflib\n",
    "import time\n",
    "import gc\n",
    "import itertools\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from models_utils_fe import *\n",
    "from models_utils_gbm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/scripts/features/'\n",
    "feats_src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/data/features/uncleaned/'\n",
    "trans_src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/data/features/lemmatized_fullclean/transformations/'\n",
    "\n",
    "wmd = pd.read_csv(src + 'train_WMD_cleaned_stemmed.csv')\n",
    "wmd = wmd.astype('float32')\n",
    "wmd.replace(np.inf, 1000, inplace = True)\n",
    "\n",
    "skip_thought = pd.read_csv(src + 'train_skipthoughts_Alex_distances.csv')\n",
    "skip_thought = skip_thought.astype('float32')\n",
    "\n",
    "compression = pd.read_csv(src + 'train_LZMAcompression_distance.csv')\n",
    "compression = compression.astype('float32')\n",
    "\n",
    "edit = pd.read_csv(src + 'train_EDITdistance.csv')\n",
    "edit = edit.astype('float32')\n",
    "\n",
    "moments = pd.read_csv(src + 'train_doc2vec_moments.csv')\n",
    "moments = moments.astype('float32')\n",
    "\n",
    "networks_NER = pd.read_csv(src + 'train_networkfeats_NER.csv')\n",
    "networks_NER = networks_NER.astype('float32')\n",
    "\n",
    "xgb_feats = pd.read_csv(feats_src + '/the_1owl/owl_train.csv')\n",
    "y_train = xgb_feats[['is_duplicate']]\n",
    "\n",
    "lsaq1 = pd.DataFrame(np.load(trans_src + 'train_lsa50_CV1gram.npy')[0])\n",
    "lsaq1.columns = ['{}_lsaCV1_q1'.format(i) for i in range(lsaq1.shape[1])]\n",
    "lsaq2 = pd.DataFrame(np.load(trans_src + 'train_lsa50_CV1gram.npy')[1])\n",
    "lsaq2.columns = ['{}_lsaCV1_q2'.format(i) for i in range(lsaq2.shape[1])]\n",
    "\n",
    "svdq1 = pd.DataFrame(np.load(trans_src + 'train_svd50_CV1gram.npy')[0])\n",
    "svdq1.columns = ['{}_svdCV1_q1'.format(i) for i in range(svdq1.shape[1])]\n",
    "svdq2 = pd.DataFrame(np.load(trans_src + 'train_svd50_CV1gram.npy')[1])\n",
    "svdq2.columns = ['{}_svdCV1_q2'.format(i) for i in range(svdq2.shape[1])]\n",
    "\n",
    "\n",
    "X_train = pd.read_pickle('Xtrain_500bestCols.pkl')\n",
    "X_train = pd.concat([X_train, wmd, skip_thought, compression, edit, moments, networks_NER, \n",
    "                     lsaq1, lsaq2, svdq1, svdq2], axis = 1)\n",
    "\n",
    "del xgb_feats, wmd, skip_thought, compression, edit, moments, networks_NER, \\\n",
    "    lsaq1, lsaq2, svdq1, svdq2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_cols = [\n",
    "    'min_pagerank_sp_network_weighted',\n",
    "    'norm_wmd',\n",
    "    'word_match',\n",
    "    '1wl_tfidf_l2_euclidean',\n",
    "    'm_vstack_svd_q1_q1_euclidean',\n",
    "    '1wl_tfidf_cosine',\n",
    "    'sk_bi_skew_q2vec',\n",
    "    'm_q1_q2_tf_svd0',\n",
    "    'sk_bi_skew_q1vec',\n",
    "    'skew_q2vec',\n",
    "    'trigram_tfidf_cosine',\n",
    "    'sk_uni_skew_q2vec',\n",
    "    'sk_bi_canberra_distance',\n",
    "    'question1_3',\n",
    "    'sk_uni_skew_q1vec',\n",
    "    'sk_uni_kur_q2vec',\n",
    "    'min_eigenvector_centrality_np_network_weighted',\n",
    "    'avg_world_len2',\n",
    "    'z_word_match',\n",
    "    'sk_uni_kur_q1vec',\n",
    "    'skew_doc2vec_pretrained_lemmat']\n",
    "\n",
    "rescale = False\n",
    "X_bin = bin_numerical(X_train, best_cols, 0.1)\n",
    "X_grouped = group_featbyfeat(X_train, best_cols, 'mean')\n",
    "X_grouped2 = group_featbyfeat(X_train, best_cols, 'sum')\n",
    "X_combinations = feature_combinations(X_train, best_cols[:5])\n",
    "\n",
    "X_additional = pd.concat([X_bin, X_grouped, X_grouped2, X_combinations], axis = 1)\n",
    "X_additional = drop_duplicate_cols(X_additional)\n",
    "X_additional.replace(np.inf, 999, inplace = True)\n",
    "X_additional.replace(np.nan, -999, inplace = True)\n",
    "if rescale:\n",
    "    colnames = X_additional.columns\n",
    "    X_additional = pd.DataFrame(MinMaxScaler().fit_transform(X_additional))\n",
    "    X_additional.columns = colnames\n",
    "\n",
    "X_train = pd.concat([X_train, X_additional], axis = 1)\n",
    "X_train = X_train.astype('float32')\n",
    "print('Final training data shape:', X_train.shape)\n",
    "\n",
    "del X_bin, X_grouped, X_grouped2, X_combinations, X_additional\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/scripts/features/'\n",
    "feats_src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/data/features/uncleaned/'\n",
    "trans_src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/data/features/lemmatized_fullclean/transformations/'\n",
    "\n",
    "X_train = pd.read_pickle('Xtrain_814colsBest.pkl', compression = 'bz2')\n",
    "xgb_feats = pd.read_csv(feats_src + '/the_1owl/owl_train.csv')\n",
    "y_train = xgb_feats[['is_duplicate']]\n",
    "\n",
    "\n",
    "del xgb_feats\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training with parameters: {'nthread': 4, 'colsample_bytree': 0.42, 'eta': 0.02, 'max_depth': 8, 'objective': 'binary:logistic', 'subsample': 0.85, 'eval_metric': 'logloss', 'min_child_weight': 20, 'silent': 1, 'tree_method': 'hist', 'seed': 1337}\n",
      "[0]\ttrain-logloss:0.680122\tvalid-logloss:0.680223\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 250 rounds.\n",
      "[100]\ttrain-logloss:0.274051\tvalid-logloss:0.280521\n",
      "[200]\ttrain-logloss:0.227292\tvalid-logloss:0.237365\n",
      "[300]\ttrain-logloss:0.21292\tvalid-logloss:0.226354\n",
      "[400]\ttrain-logloss:0.201778\tvalid-logloss:0.220382\n",
      "[500]\ttrain-logloss:0.192838\tvalid-logloss:0.216636\n",
      "[600]\ttrain-logloss:0.185062\tvalid-logloss:0.213893\n",
      "[700]\ttrain-logloss:0.178618\tvalid-logloss:0.211966\n",
      "[800]\ttrain-logloss:0.173117\tvalid-logloss:0.210567\n",
      "[900]\ttrain-logloss:0.167968\tvalid-logloss:0.20939\n",
      "[1000]\ttrain-logloss:0.163199\tvalid-logloss:0.208437\n",
      "[1100]\ttrain-logloss:0.158802\tvalid-logloss:0.207618\n",
      "[1200]\ttrain-logloss:0.154606\tvalid-logloss:0.206917\n",
      "[1300]\ttrain-logloss:0.150681\tvalid-logloss:0.206357\n",
      "[1400]\ttrain-logloss:0.146821\tvalid-logloss:0.205809\n",
      "[1500]\ttrain-logloss:0.143423\tvalid-logloss:0.205313\n",
      "[1600]\ttrain-logloss:0.139832\tvalid-logloss:0.204876\n",
      "[1700]\ttrain-logloss:0.136387\tvalid-logloss:0.204411\n",
      "[1800]\ttrain-logloss:0.133093\tvalid-logloss:0.204063\n",
      "[1900]\ttrain-logloss:0.129738\tvalid-logloss:0.203605\n",
      "[2000]\ttrain-logloss:0.126639\tvalid-logloss:0.203304\n",
      "[2100]\ttrain-logloss:0.123697\tvalid-logloss:0.202996\n",
      "[2200]\ttrain-logloss:0.120948\tvalid-logloss:0.202741\n",
      "[2300]\ttrain-logloss:0.118149\tvalid-logloss:0.20249\n",
      "[2400]\ttrain-logloss:0.115491\tvalid-logloss:0.202264\n",
      "[2500]\ttrain-logloss:0.112829\tvalid-logloss:0.202043\n",
      "[2600]\ttrain-logloss:0.110168\tvalid-logloss:0.201783\n",
      "[2700]\ttrain-logloss:0.107845\tvalid-logloss:0.20159\n",
      "[2800]\ttrain-logloss:0.105434\tvalid-logloss:0.201451\n",
      "[2900]\ttrain-logloss:0.103155\tvalid-logloss:0.201279\n",
      "[3000]\ttrain-logloss:0.100872\tvalid-logloss:0.20112\n",
      "[3100]\ttrain-logloss:0.09865\tvalid-logloss:0.201039\n",
      "[3200]\ttrain-logloss:0.096574\tvalid-logloss:0.200971\n",
      "[3300]\ttrain-logloss:0.094473\tvalid-logloss:0.200876\n",
      "[3400]\ttrain-logloss:0.092543\tvalid-logloss:0.200812\n",
      "[3500]\ttrain-logloss:0.09066\tvalid-logloss:0.200733\n",
      "[3600]\ttrain-logloss:0.088758\tvalid-logloss:0.200654\n",
      "[3700]\ttrain-logloss:0.086787\tvalid-logloss:0.200555\n",
      "[3800]\ttrain-logloss:0.085087\tvalid-logloss:0.200527\n",
      "[3900]\ttrain-logloss:0.083296\tvalid-logloss:0.200455\n",
      "[4000]\ttrain-logloss:0.08152\tvalid-logloss:0.200397\n",
      "[4100]\ttrain-logloss:0.079818\tvalid-logloss:0.200295\n",
      "[4200]\ttrain-logloss:0.078233\tvalid-logloss:0.200288\n",
      "[4300]\ttrain-logloss:0.076603\tvalid-logloss:0.200224\n",
      "[4400]\ttrain-logloss:0.075042\tvalid-logloss:0.20023\n",
      "[4500]\ttrain-logloss:0.073516\tvalid-logloss:0.20019\n",
      "[4600]\ttrain-logloss:0.072041\tvalid-logloss:0.200171\n",
      "[4700]\ttrain-logloss:0.070518\tvalid-logloss:0.200209\n",
      "Stopping. Best iteration:\n",
      "[4515]\ttrain-logloss:0.07331\tvalid-logloss:0.200167\n",
      "\n",
      "Start predicting...\n",
      "Final score: 0.200167422056 \n",
      " Time it took to train and predict: 5234.663367986679\n"
     ]
    }
   ],
   "source": [
    "xgb = True\n",
    "\n",
    "if xgb:\n",
    "    run_xgb(X_train, y_train)\n",
    "else:\n",
    "    run_lgb(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gbm = xgb.Booster(model_file = 'saved_models/XGB/XGB_500cols_experiments.txt')\n",
    "dtrain = xgb.DMatrix(X_train, label = y_train)\n",
    "\n",
    "mapper = {'f{0}'.format(i): v for i, v in enumerate(dtrain.feature_names)}\n",
    "importance = {mapper[k]: v for k, v in gbm.get_fscore().items()}\n",
    "importance = sorted(importance.items(), key=lambda x:x[1], reverse=True)[:20]\n",
    "\n",
    "df_importance = pd.DataFrame(importance, columns=['feature', 'fscore'])\n",
    "df_importance['fscore'] = df_importance['fscore'] / df_importance['fscore'].sum()\n",
    "\n",
    "plt.figure()\n",
    "df_importance.plot()\n",
    "df_importance.plot(kind='barh', x='feature', y='fscore', legend=False, figsize=(10, 18))\n",
    "plt.title('XGBoost Feature Importance')\n",
    "plt.xlabel('relative importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "retain_cols = df_importance['feature']\n",
    "X_train2 = X_train.loc[:, retain_cols]\n",
    "retain_cols.to_pickle('Colnames_best500features.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
