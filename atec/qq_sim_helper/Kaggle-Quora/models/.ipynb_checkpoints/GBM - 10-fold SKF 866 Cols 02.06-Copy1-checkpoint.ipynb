{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import difflib\n",
    "import time\n",
    "import gc\n",
    "import itertools\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from models_utils_fe import *\n",
    "from models_utils_skf import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404290, 866)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/scripts/features/'\n",
    "feats_src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/data/features/uncleaned/'\n",
    "\n",
    "X_train = pd.read_pickle('Xtrain_866BestColsDropped.pkl')\n",
    "X_train = X_train.astype('float32')\n",
    "print(X_train.shape)\n",
    "\n",
    "xgb_feats = pd.read_csv(feats_src + '/the_1owl/owl_train.csv')\n",
    "y_train = xgb_feats[['is_duplicate']]\n",
    "\n",
    "del xgb_feats\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgb_foldrun_ooftr(X, y, params, name, start_fold, save = True):\n",
    "    skf = StratifiedKFold(n_splits = 10, random_state = 111, shuffle = True)\n",
    "    if isinstance(X, pd.core.frame.DataFrame):\n",
    "        X = X.values\n",
    "    if isinstance(y, pd.core.frame.DataFrame):\n",
    "        y = y.is_duplicate.values\n",
    "    if isinstance(y, pd.core.frame.Series):\n",
    "        y = y.values\n",
    "    print('Running XGB model with parameters:', params)\n",
    "    \n",
    "    j = 0\n",
    "    losses = []\n",
    "    train_splits = []\n",
    "    val_splits = []\n",
    "    for tr_index, val_index in skf.split(X, y):\n",
    "        train_splits.append(tr_index)\n",
    "        val_splits.append(val_index)\n",
    "        \n",
    "    oof_train = np.zeros((X.shape[0]))\n",
    "    os.makedirs('saved_models/XGB/SKF/{}'.format(name), exist_ok = True)\n",
    "    for i in range(start_fold, 10):\n",
    "        X_tr, X_val = X[train_splits[i]], X[val_splits[i]]\n",
    "        y_tr, y_val = y[train_splits[i]], y[val_splits[i]]\n",
    "        t = time.time()\n",
    "        \n",
    "        dtrain = xgb.DMatrix(X_tr, label = y_tr)\n",
    "        dval = xgb.DMatrix(X_val, label = y_val)\n",
    "        watchlist = [(dtrain, 'train'), (dval, 'valid')]\n",
    "        print('Start training on fold: {}'.format(i))\n",
    "        gbm = xgb.train(params, dtrain, 10000, watchlist, \n",
    "                        early_stopping_rounds = 200, verbose_eval = 100)\n",
    "        print('Start predicting...')\n",
    "        val_pred = gbm.predict(xgb.DMatrix(X_val), ntree_limit=gbm.best_ntree_limit)\n",
    "        oof_train[val_index] = val_pred\n",
    "        score = log_loss(y_val, val_pred)\n",
    "        losses.append(score)\n",
    "        print('Final score for fold {} :'.format(i), score, '\\n',\n",
    "              'Time it took to train and predict on fold:', time.time() - t, '\\n')\n",
    "        gbm.save_model('saved_models/XGB/SKF/{}/XGB_10SKF_loss{:.5f}_fold{}.txt'.format(name, score, i))\n",
    "        j += 1\n",
    "    print('Mean logloss for model in 10-folds SKF:', np.array(losses).mean(axis = 0))\n",
    "    oof_train = pd.DataFrame(oof_train)\n",
    "    oof_train.columns = ['{}_prob'.format(name)]\n",
    "    if save:\n",
    "        oof_train.to_pickle('OOF_preds/train/train_preds_{}.pkl'.format(name))\n",
    "    return oof_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgb_foldrun_ooftr(X, y, params, name, src, save = True):\n",
    "    skf = StratifiedKFold(n_splits = 10, random_state = 111, shuffle = True)\n",
    "    if isinstance(X, pd.core.frame.DataFrame):\n",
    "        X = X.values\n",
    "    if isinstance(y, pd.core.frame.DataFrame):\n",
    "        y = y.is_duplicate.values\n",
    "    if isinstance(y, pd.core.frame.Series):\n",
    "        y = y.values\n",
    "    print('Running XGB model with parameters:', params)\n",
    "    \n",
    "    j = 0\n",
    "    losses = []\n",
    "    train_splits = []\n",
    "    val_splits = []\n",
    "    for tr_index, val_index in skf.split(X, y):\n",
    "        train_splits.append(tr_index)\n",
    "        val_splits.append(val_index)\n",
    "        \n",
    "    oof_train = np.zeros((X.shape[0]))\n",
    "    models = sorted([x for x in os.listdir(src) if 'txt' in x])\n",
    "    for i in range(0, 10):\n",
    "        X_tr, X_val = X[train_splits[i]], X[val_splits[i]]\n",
    "        y_tr, y_val = y[train_splits[i]], y[val_splits[i]]\n",
    "        t = time.time()\n",
    "        \n",
    "        dtrain = xgb.DMatrix(X_tr, label = y_tr)\n",
    "        dval = xgb.DMatrix(X_val, label = y_val)\n",
    "        watchlist = [(dtrain, 'train'), (dval, 'valid')]\n",
    "        print('Start training on fold: {}'.format(i))\n",
    "        gbm = xgb.Booster(model_file = src + models[i])\n",
    "        \n",
    "        print('Start predicting...')\n",
    "        val_pred = gbm.predict(xgb.DMatrix(X_val))\n",
    "        oof_train[val_splits[i]] = val_pred\n",
    "        score = log_loss(y_val, val_pred)\n",
    "        losses.append(score)\n",
    "        print('Final score for fold {} :'.format(i), score, '\\n',\n",
    "              'Time it took to train and predict on fold:', time.time() - t, '\\n')\n",
    "    print('Mean logloss for model in 10-folds SKF:', np.array(losses).mean(axis = 0))\n",
    "    oof_train = pd.DataFrame(oof_train)\n",
    "    oof_train.columns = ['{}_prob'.format(name)]\n",
    "    if save:\n",
    "        oof_train.to_pickle('OOF_preds/train/train_preds_{}.pkl'.format(name))\n",
    "    return oof_train\n",
    "\n",
    "def predict_test_xgb_fold(src, X_test):\n",
    "    print('Predicting on test set with XGBoost.')\n",
    "    fold_preds = np.zeros((10, 2345796))\n",
    "    models = sorted([x for x in os.listdir(src) if 'txt' in x])\n",
    "    #X_test = xgb.DMatrix(X_test)\n",
    "    for i in tqdm(range(len(models))):\n",
    "        gbm = xgb.Booster(model_file = src + models[i])\n",
    "        test_preds = gbm.predict(X_test)\n",
    "        test_preds = np.apply_along_axis(transform, 0, test_preds)\n",
    "        fold_preds[i, :] = test_preds\n",
    "    fold_preds = fold_preds.mean(axis = 0)\n",
    "    sub_src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/submissions/'\n",
    "    sample_sub = pd.read_csv(sub_src + 'sample_submission.csv')\n",
    "    sample_sub['is_duplicate'] = fold_preds\n",
    "    #sample_sub.is_duplicate = sample_sub.is_duplicate.apply(transform)\n",
    "    sample_sub.to_csv(sub_src + '{}.csv'.format(src.split('/')[-2]), index = False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running XGB model with parameters: {'nthread': 4, 'seed': 1337, 'max_depth': 5, 'eval_metric': 'logloss', 'objective': 'binary:logistic', 'colsample_bytree': 0.43, 'subsample': 0.88, 'silent': 1, 'eta': 0.02, 'tree_method': 'hist', 'min_child_weight': 30}\n",
      "Start training on fold: 0\n",
      "Start predicting...\n",
      "Final score for fold 0 : 0.176475939391 \n",
      " Time it took to train and predict on fold: 5.173024654388428 \n",
      "\n",
      "Start training on fold: 1\n",
      "Start predicting...\n",
      "Final score for fold 1 : 0.184859639179 \n",
      " Time it took to train and predict on fold: 8.121746063232422 \n",
      "\n",
      "Start training on fold: 2\n",
      "Start predicting...\n",
      "Final score for fold 2 : 0.180010402118 \n",
      " Time it took to train and predict on fold: 6.373630046844482 \n",
      "\n",
      "Start training on fold: 3\n",
      "Start predicting...\n",
      "Final score for fold 3 : 0.177431577293 \n",
      " Time it took to train and predict on fold: 7.068759202957153 \n",
      "\n",
      "Start training on fold: 4\n",
      "Start predicting...\n",
      "Final score for fold 4 : 0.182519865556 \n",
      " Time it took to train and predict on fold: 5.904279708862305 \n",
      "\n",
      "Start training on fold: 5\n",
      "Start predicting...\n",
      "Final score for fold 5 : 0.179689801945 \n",
      " Time it took to train and predict on fold: 7.627161264419556 \n",
      "\n",
      "Start training on fold: 6\n",
      "Start predicting...\n",
      "Final score for fold 6 : 0.180951319709 \n",
      " Time it took to train and predict on fold: 7.141423940658569 \n",
      "\n",
      "Start training on fold: 7\n",
      "Start predicting...\n",
      "Final score for fold 7 : 0.178558171648 \n",
      " Time it took to train and predict on fold: 7.204513788223267 \n",
      "\n",
      "Start training on fold: 8\n",
      "Start predicting...\n",
      "Final score for fold 8 : 0.181894936618 \n",
      " Time it took to train and predict on fold: 5.9274115562438965 \n",
      "\n",
      "Start training on fold: 9\n",
      "Start predicting...\n",
      "Final score for fold 9 : 0.181624612606 \n",
      " Time it took to train and predict on fold: 7.277164459228516 \n",
      "\n",
      "Mean logloss for model in 10-folds SKF: 0.180401626606\n"
     ]
    }
   ],
   "source": [
    "xgb_params2 = {\n",
    "    'seed': 1337,\n",
    "    'colsample_bytree': 0.43,\n",
    "    'silent': 1,\n",
    "    'subsample': 0.88,\n",
    "    'eta': 0.02,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'max_depth': 5,\n",
    "    'min_child_weight': 30,\n",
    "    'nthread': 4,\n",
    "    'tree_method': 'hist',\n",
    "    }\n",
    "\n",
    "\n",
    "src1 = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/scripts/models/saved_models/XGB/SKF/866cols_xgbparams2_copy/'\n",
    "oof_train2 = xgb_foldrun_ooftr(X_train, y_train, xgb_params2, '866cols_xgbparams2', src1, save = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb_params1 = {\n",
    "    'seed': 1337,\n",
    "    'colsample_bytree': 0.46,\n",
    "    'silent': 1,\n",
    "    'subsample': 0.89,\n",
    "    'eta': 0.02,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'max_depth': 8,\n",
    "    'min_child_weight': 21,\n",
    "    'nthread': 4,\n",
    "    'tree_method': 'hist',\n",
    "    }\n",
    "\n",
    "xgb_params2 = {\n",
    "    'seed': 1337,\n",
    "    'colsample_bytree': 0.43,\n",
    "    'silent': 1,\n",
    "    'subsample': 0.88,\n",
    "    'eta': 0.02,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'max_depth': 5,\n",
    "    'min_child_weight': 30,\n",
    "    'nthread': 4,\n",
    "    'tree_method': 'hist',\n",
    "    }\n",
    "\n",
    "xgb_params3 = {\n",
    "    'seed': 1337,\n",
    "    'colsample_bytree': 0.38,\n",
    "    'silent': 1,\n",
    "    'subsample': 0.87,\n",
    "    'eta': 0.02,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'max_depth': 10,\n",
    "    'min_child_weight': 16,\n",
    "    'nthread': 4,\n",
    "    'tree_method': 'hist',\n",
    "    }\n",
    "\n",
    "xgb_params4 = {\n",
    "    'seed': 1337,\n",
    "    'colsample_bytree': 0.46,\n",
    "    'silent': 1,\n",
    "    'subsample': 0.88,\n",
    "    'eta': 0.02,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'max_depth': 7,\n",
    "    'min_child_weight': 23,\n",
    "    'nthread': 4,\n",
    "    'tree_method': 'hist',\n",
    "    }\n",
    "\n",
    "\n",
    "#oof_train3 = xgb_foldrun_ooftr(X_train, y_train, xgb_params3, '866cols_xgbparams3')\n",
    "#oof_train4 = xgb_foldrun_ooftr(X_train, y_train, xgb_params4, '866cols_xgbparams4')\n",
    "oof_train2 = xgb_foldrun_ooftr(X_train, y_train, xgb_params2, '866cols_xgbparams2', 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 866cols_xgbparams1: Mean logloss for model in 10-folds SKF: 0.179874240765\n",
    "* 866cols_xgbparams3: Mean logloss for model in 10-folds SKF: 0.180440278734\n",
    "* 866cols_xgbparams4: Mean logloss for model in 10-folds SKF: 0.179872296735\n",
    "* 866cols_xgbparams2: Mean logloss for model in 10-folds SKF: 0.180740034549"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
