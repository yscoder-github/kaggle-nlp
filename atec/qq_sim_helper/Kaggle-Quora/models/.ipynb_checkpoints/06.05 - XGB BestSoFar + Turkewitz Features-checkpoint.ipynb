{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from sklearn.metrics import log_loss\n",
    "from scipy.optimize import minimize\n",
    "import multiprocessing\n",
    "import difflib\n",
    "import time\n",
    "import gc\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from xgb_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train():\n",
    "    keras_q1 = np.load('../features/q1train_spacylemmat_fullclean_170len_treetrunc.npy')\n",
    "    keras_q2 = np.load('../features/q2train_spacylemmat_fullclean_170len_treetrunc.npy')\n",
    "    xgb_feats = pd.read_csv('../../data/features/the_1owl/owl_train.csv')\n",
    "    abhishek_feats = pd.read_csv('../../data/features/abhishek/train_features.csv',\n",
    "                              encoding = 'ISO-8859-1').iloc[:, 2:]\n",
    "    text_feats = pd.read_csv('../../data/features/other_features/text_features_train.csv',\n",
    "                            encoding = 'ISO-8859-1')\n",
    "    img_feats = pd.read_csv('../../data/features/other_features/img_features_train.csv')\n",
    "    srk_feats = pd.read_csv('../../data/features/srk/SRK_grams_features_train.csv')\n",
    "    turkewitz_feats = pd.read_csv('../../data/features/lemmat_spacy_features/train_turkewitz_features.csv')\n",
    "    turkewitz_feats = turkewitz_feats[['q1_freq', 'q2_freq']]\n",
    "\n",
    "    xgb_feats.drop(['z_len1', 'z_len2', 'z_word_len1', 'z_word_len2'], axis = 1, inplace = True)\n",
    "    y_train = xgb_feats['is_duplicate']\n",
    "    xgb_feats = xgb_feats.iloc[:, 8:]\n",
    "    \n",
    "    X_train2 = np.concatenate([keras_q1, keras_q2, xgb_feats, abhishek_feats, text_feats, img_feats, \n",
    "                               turkewitz_feats], axis = 1)\n",
    "    for i in range(X_train2.shape[1]):\n",
    "        if np.sum(X_train2[:, i] == y_train.values) == X_train2.shape[0]:\n",
    "            print('LEAK FOUND')\n",
    "    \n",
    "    X_train2 = X_train2.astype('float32')\n",
    "    X_train2 = pd.DataFrame(X_train2)\n",
    "    X_train2['is_duplicate'] = y_train\n",
    "    print('Training data shape:', X_train2.shape)\n",
    "    return X_train2, y_train\n",
    "\n",
    "def get_test():\n",
    "    keras_q1 = np.load('../features/q1train_spacylemmat_fullclean_170len_treetrunc.npy')\n",
    "    keras_q2 = np.load('../features/q2train_spacylemmat_fullclean_170len_treetrunc.npy')\n",
    "    xgb_feats = pd.read_csv('../../data/features/the_1owl/owl_test.csv')\n",
    "    abhishek_feats = pd.read_csv('../../data/features/abhishek/test_features.csv',\n",
    "                              encoding = 'ISO-8859-1').iloc[:, 2:]\n",
    "    text_feats = pd.read_csv('../../data/features/other_features/text_features_test.csv',\n",
    "                            encoding = 'ISO-8859-1')\n",
    "    img_feats = pd.read_csv('../../data/features/other_features/img_features_test.csv')\n",
    "    srk_feats = pd.read_csv('../../data/features/srk/SRK_grams_features_test.csv')\n",
    "    turkewitz_feats = pd.read_csv('../../data/features/lemmat_spacy_features/test_turkewitz_features.csv')\n",
    "    turkewitz_feats = turkewitz_feats[['q1_freq', 'q2_freq']]\n",
    "\n",
    "    xgb_feats.drop(['z_len1', 'z_len2', 'z_word_len1', 'z_word_len2'], axis = 1, inplace = True)\n",
    "    xgb_feats = xgb_feats.iloc[:, 5:]\n",
    "    \n",
    "    X_test2 = np.concatenate([keras_q1, keras_q2, xgb_feats, abhishek_feats, text_feats, img_feats,\n",
    "                             turkewitz_feats], axis = 1)\n",
    "\n",
    "    X_test2 = X_test2.astype('float32')\n",
    "    X_test2 = pd.DataFrame(X_test2)\n",
    "    print('Test data shape:', X_test2.shape)\n",
    "    return X_test2\n",
    "\n",
    "def predict_test(model_name):\n",
    "    print('Predicting on test set.')\n",
    "    X_test = get_test()\n",
    "    gbm = xgb.Booster(model_file = 'saved_models/XGB/{}.txt'.format(model_name))\n",
    "    test_preds = gbm.predict(xgb.DMatrix(X_test))\n",
    "\n",
    "    sub_src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/submissions/'\n",
    "    sample_sub = pd.read_csv(sub_src + 'sample_submission.csv')\n",
    "    sample_sub['is_duplicate'] = test_preds\n",
    "    sample_sub.is_duplicate = sample_sub.is_duplicate.apply(transform)\n",
    "    sample_sub.to_csv(sub_src + '{}.csv'.format(model_name), index = False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_xgb(cv = False):\n",
    "    \n",
    "    t = time.time()\n",
    "    params = {\n",
    "    'seed': 1337,\n",
    "    'colsample_bytree': 0.48,\n",
    "    'silent': 1,\n",
    "    'subsample': 0.74,\n",
    "    'eta': 0.05,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'max_depth': 12,\n",
    "    'min_child_weight': 20,\n",
    "    'nthread': 8,\n",
    "    'tree_method': 'hist',\n",
    "    #'updater': 'grow_gpu',\n",
    "    }\n",
    "    \n",
    "    X_train, y_train = get_train()\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_train.drop(['is_duplicate'], axis = 1, inplace = True)\n",
    "    \n",
    "    if cv:\n",
    "        dtrain = xgb.DMatrix(X_train, y_train)\n",
    "        hist = xgb.cv(params, dtrain, num_boost_round = 100000, nfold = 5,\n",
    "                      stratified = True, early_stopping_rounds = 350, verbose_eval = 250,\n",
    "                      seed = 1337)\n",
    "        del X_train, y_train\n",
    "        gc.collect()\n",
    "        print('Time it took to train in CV manner:', time.time() - t)\n",
    "        return hist\n",
    "    \n",
    "    else:\n",
    "        X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, stratify = y_train,\n",
    "                                                    test_size = 0.2, random_state = 111)\n",
    "        del X_train, y_train\n",
    "        gc.collect()\n",
    "        dtrain = xgb.DMatrix(X_tr, label = y_tr)\n",
    "        dval = xgb.DMatrix(X_val, label = y_val)\n",
    "        watchlist = [(dtrain, 'train'), (dval, 'valid')]\n",
    "\n",
    "        print('Start training...')\n",
    "        gbm = xgb.train(params, dtrain, 100000, watchlist, \n",
    "                        early_stopping_rounds = 350, verbose_eval = 250)\n",
    "\n",
    "        print('Start predicting...')\n",
    "        val_pred = gbm.predict(xgb.DMatrix(X_val), ntree_limit=gbm.best_ntree_limit)\n",
    "        score = log_loss(y_val, val_pred)\n",
    "        print('Final score:', score, '\\n', 'Time it took to train and predict:', time.time() - t)\n",
    "        \n",
    "        del X_tr, X_val, y_tr, y_val\n",
    "        gc.collect()\n",
    "        return gbm\n",
    "    \n",
    "\n",
    "def run_xgb(model_name, train = True, test = False, cv = False):\n",
    "    if cv:\n",
    "        gbm_hist = train_xgb(True)\n",
    "        return gbm_hist\n",
    "    if train:\n",
    "        gbm = train_xgb()\n",
    "        gbm.save_model('saved_models/XGB/{}.txt'.format(model_name))\n",
    "        if test:\n",
    "            predict_test('{}'.format(model_name))\n",
    "        return gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = run_xgb('XGB_firstBO_turkewitz_Qspacyencode', train = True, test = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test('XGB_firstBO_turkewitz_Qspacyencode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
