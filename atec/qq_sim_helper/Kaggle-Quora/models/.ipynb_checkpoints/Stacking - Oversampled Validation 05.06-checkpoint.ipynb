{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from models_utils_skf import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_oof(mode = 'train'):\n",
    "    src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/scripts/models/OOF_preds/'\n",
    "    oof_preds = pd.DataFrame()\n",
    "    files = sorted([x for x in os.listdir(src + '{}/'.format(mode)) if '.pkl' in x or '.csv' in x\n",
    "                   and 'stack' not in x])\n",
    "    print('\\n', 'Loading OOF preds:', files, '\\n', 'Numer of files to load:', len(files), '\\n')\n",
    "    for i in files:\n",
    "        if 'pkl'in i:\n",
    "            df_preds = pd.read_pickle('{}/{}/{}'.format(src, mode, i))\n",
    "            if 'id' in df_preds.columns:\n",
    "                df_preds.drop(['id'], axis = 1, inplace = True)\n",
    "            if 'test_id' in df_preds.columns:\n",
    "                df_preds.drop(['test_id'], axis = 1, inplace = True)\n",
    "        if '.csv'in i:\n",
    "            df_preds = pd.read_csv('{}/{}/{}'.format(src, mode, i))\n",
    "            if 'id' in df_preds.columns:\n",
    "                df_preds.drop(['id'], axis = 1, inplace = True)\n",
    "            if 'test_id' in df_preds.columns:\n",
    "                df_preds.drop(['test_id'], axis = 1, inplace = True)\n",
    "        oof_preds = pd.concat([oof_preds, df_preds], axis = 1)\n",
    "    return oof_preds\n",
    "\n",
    "def transform(x):\n",
    "    a = 0.165 / 0.369191399096\n",
    "    b =  (1 - 0.165) / (1 - 0.369191399096)\n",
    "    xt = a * x / (a * x + b * (1 - x))\n",
    "    return xt\n",
    "\n",
    "def inv_pred_transform(preds):\n",
    "    a = 0.165 / 0.369191399096\n",
    "    b = (1 - 0.165) / (1 - 0.369191399096)\n",
    "    return b * preds / (b * preds + a * (1 - preds))\n",
    "\n",
    "def testOOF_transform(X_test2, inverse = True):\n",
    "    X_test = X_test2.copy()\n",
    "    for i in range(X_test.shape[1]):\n",
    "        if inverse:\n",
    "            X_test.iloc[:, i] = X_test.iloc[:, i].apply(inv_pred_transform)\n",
    "        else:\n",
    "            X_test.iloc[:, i] = X_test.iloc[:, i].apply(transform)\n",
    "    return X_test\n",
    "\n",
    "def predict_test_lgbm(test_preds, model_name, transform_preds = True):\n",
    "    print('Predicting on test set with LightGBM.')\n",
    "    sub_src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/submissions/'\n",
    "    sample_sub = pd.read_csv(sub_src + 'sample_submission.csv')\n",
    "    sample_sub['is_duplicate'] = test_preds\n",
    "    if transform_preds:\n",
    "        sample_sub.is_duplicate = sample_sub.is_duplicate.apply(transform)\n",
    "        sample_sub.to_csv(sub_src + '{}_transformed.csv'.format(model_name), index = False)\n",
    "    else:\n",
    "        sample_sub.to_csv(sub_src + '{}.csv'.format(model_name), index = False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def oversample_anokas(X, y):\n",
    "    pos_train = X[y == 1]\n",
    "    neg_train = X[y == 0]\n",
    "    p = 0.165\n",
    "    scale = ((len(pos_train) / (len(pos_train) + len(neg_train))) / p) - 1\n",
    "    while scale > 1:\n",
    "        neg_train = np.vstack([neg_train, neg_train])\n",
    "        scale -=1\n",
    "    neg_train = np.vstack([neg_train, neg_train[:int(scale * len(neg_train))]])\n",
    "    print(\"Mean target rate : \", len(pos_train) / (len(pos_train) + len(neg_train)))\n",
    "    X = np.vstack([pos_train, neg_train])\n",
    "    y = (np.zeros(len(pos_train)) + 1).tolist() + np.zeros(len(neg_train)).tolist()\n",
    "    del pos_train, neg_train\n",
    "    return X, y\n",
    "\n",
    "def oversample_2nd(X, y):\n",
    "    X_dup = X[y == 1]\n",
    "    X_non_dup = X[y == 0]\n",
    "    X = np.vstack([X_non_dup, X_dup, X_non_dup])\n",
    "    y = np.array([0] * X_non_dup.shape[0] + [1] * X_dup.shape[0] + [0] * X_non_dup.shape[0])\n",
    "    del X_dup\n",
    "    del X_non_dup\n",
    "    print(\"Mean target rate : \", y.mean())\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def lgb_foldrun_test_oversample(X, y, X_test, params, name, save = True):\n",
    "    skf = StratifiedKFold(n_splits = 10, random_state = 111, shuffle = True)\n",
    "    if isinstance(X, pd.core.frame.DataFrame):\n",
    "        X = X.values\n",
    "    if isinstance(y, pd.core.frame.DataFrame):\n",
    "        y = y.is_duplicate.values\n",
    "    if isinstance(y, pd.core.frame.Series):\n",
    "        y = y.values\n",
    "    print('Running LGBM model with parameters:', params)\n",
    "        \n",
    "    i = 0\n",
    "    losses = []\n",
    "    losses2 = []\n",
    "    oof_train = np.zeros((X.shape[0]))\n",
    "    oof_test = np.zeros((10, 2345796))\n",
    "    os.makedirs('saved_models/LGBM/SKF/{}'.format(name), exist_ok = True)\n",
    "    for tr_index, val_index in skf.split(X, y):\n",
    "        X_tr, X_val = X[tr_index], X[val_index]\n",
    "        y_tr, y_val = y[tr_index], y[val_index]\n",
    "        t = time.time()\n",
    "        \n",
    "        X_tr, y_tr = oversample_anokas(X_tr, y_tr)\n",
    "        X_val, y_val = oversample_anokas(X_val, y_val)\n",
    "        \n",
    "        lgb_train = lgb.Dataset(X_tr, y_tr)\n",
    "        lgb_val = lgb.Dataset(X_val, y_val)\n",
    "        print('\\n', 'Start training on fold: {}'.format(i))\n",
    "        gbm = lgb.train(params, lgb_train, num_boost_round = 100000, valid_sets = lgb_val,\n",
    "                        early_stopping_rounds = 200, verbose_eval = 100)\n",
    "        print('Start predicting...')\n",
    "        val_pred = gbm.predict(X_val, num_iteration=gbm.best_iteration)\n",
    "        val_pred_transform = np.apply_along_axis(transform, 0, val_pred)\n",
    "        oof_train[val_index] = val_pred\n",
    "        score = log_loss(y_val, val_pred)\n",
    "        score2 = log_loss(y_val, val_pred_transform)\n",
    "        losses.append(score)\n",
    "        losses2.append(score2)\n",
    "        if X_test is not None:\n",
    "            test_preds = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "            oof_test[i, :] = test_preds\n",
    "        print('Final score for fold {} :'.format(i), score, 'Transformed score:', score2, '\\n',\n",
    "              'Time it took to train and predict on fold:', time.time() - t, '\\n')\n",
    "        gbm.save_model('saved_models/LGBM/SKF/{}/LGBM_10SKF_loss{:.5f}_fold{}.txt'.format(name, score, i))\n",
    "        i += 1\n",
    "    print('Mean logloss for model in 10-folds SKF:', np.array(losses).mean(axis = 0), '\\n',\n",
    "         'Mean logloss for transformed predictions:', np.array(losses2).mean(axis = 0), '\\n')\n",
    "    oof_train = pd.DataFrame(oof_train)\n",
    "    oof_train.columns = ['{}_prob'.format(name)]\n",
    "    oof_test = oof_test.mean(axis = 0)\n",
    "    oof_test = pd.DataFrame(oof_test)\n",
    "    oof_test.columns = ['{}_prob'.format(name)]\n",
    "    if save:\n",
    "        oof_train.to_pickle('OOF_preds/train/train_preds_{}.pkl'.format(name))\n",
    "        oof_test.to_pickle('OOF_preds/test/test_preds_{}.pkl'.format(name))\n",
    "    return oof_train, oof_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Loading OOF preds: ['train_preds_866cols_xgbparams1.pkl', 'train_preds_866cols_xgbparams2.pkl', 'train_preds_866cols_xgbparams3.pkl', 'train_preds_866cols_xgbparams4.pkl', 'train_preds_AttentionClean_preds.pkl', 'train_preds_AttentionNER_preds.pkl', 'train_preds_lgb_0.1807_20170603_1943.csv', 'train_preds_lgb_0.1842_20170527_1246.csv', 'train_preds_newNetworks_currentBest.pkl', 'train_preds_xgb_0.1800_20170601_1113.csv', 'train_preds_xgb_0.1808_20170602_0246.csv', 'train_preds_xgb_0.1812_20170603_0506.csv', 'train_preds_xgb_0.1813_20170530_0249.csv'] \n",
      " Numer of files to load: 13 \n",
      "\n",
      "\n",
      " Loading OOF preds: ['test_preds_866cols_xgbparams1.csv', 'test_preds_866cols_xgbparams2.csv', 'test_preds_866cols_xgbparams3.csv', 'test_preds_866cols_xgbparams4.csv', 'test_preds_AttentionClean_preds_transformed.pkl', 'test_preds_AttentionNER_preds_transformed.pkl', 'test_preds_lgb_0.1807_20170603_1943.csv', 'test_preds_lgb_0.1842_20170527_1246.csv', 'test_preds_newNetworks_currentBest.csv', 'test_preds_xgb_0.1800_20170601_1113.csv', 'test_preds_xgb_0.1808_20170602_0246.csv', 'test_preds_xgb_0.1812_20170603_0506.csv', 'test_preds_xgb_0.1813_20170530_0249.csv'] \n",
      " Numer of files to load: 13 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgb_params = {\n",
    "    'task' : 'train',\n",
    "    'boosting_type' : 'gbdt',\n",
    "    'objective' : 'binary',\n",
    "    'metric' : {'binary_logloss'},\n",
    "    'learning_rate' : 0.03,\n",
    "    'feature_fraction' : 0.51,\n",
    "    'bagging_fraction': 0.9,\n",
    "    'bagging_freq': 100,\n",
    "    'num_leaves' : 255,\n",
    "    'max_depth': 4,\n",
    "    'min_data_in_leaf': 23,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.41,\n",
    "    'silent': 1,\n",
    "    'random_state': 1337,\n",
    "    'verbose': 1,\n",
    "    'nthread': 4,\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'seed': 1337,\n",
    "    'colsample_bytree': 0.42,\n",
    "    'silent': 1,\n",
    "    'subsample': 0.85,\n",
    "    'eta': 0.02,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'max_depth': 4,\n",
    "    'min_child_weight': 20,\n",
    "    'nthread': 4,\n",
    "    }\n",
    "\n",
    "X_train = load_oof()\n",
    "X_test = load_oof(mode = 'test')\n",
    "y_train = pd.read_pickle('y_train.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* stacking_TrainValidOversample_testInverse: \n",
    "    * Mean logloss for model in 10-folds SKF: 0.135621201826 \n",
    "    * Mean logloss for transformed predictions: 0.15744757582 \n",
    "    \n",
    "    \n",
    "    \n",
    "* stacking_ValidOversample:\n",
    "    * Mean logloss for model in 10-folds SKF: 0.153901737106 \n",
    "    * Mean logloss for transformed predictions: 0.13636932305 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LGBM model with parameters: {'max_depth': 4, 'bagging_fraction': 0.9, 'silent': 1, 'metric': {'binary_logloss'}, 'verbose': 1, 'random_state': 1337, 'min_data_in_leaf': 23, 'learning_rate': 0.03, 'objective': 'binary', 'subsample': 0.8, 'nthread': 4, 'num_leaves': 255, 'colsample_bytree': 0.41, 'feature_fraction': 0.51, 'boosting_type': 'gbdt', 'bagging_freq': 100, 'task': 'train'}\n",
      "Mean target rate :  0.19124359014512396\n",
      "Mean target rate :  0.19124429867267975\n",
      "\n",
      " Start training on fold: 0\n",
      "Train until valid scores didn't improve in 200 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.149598\n",
      "[200]\tvalid_0's binary_logloss: 0.134213\n",
      "[300]\tvalid_0's binary_logloss: 0.133602\n",
      "[400]\tvalid_0's binary_logloss: 0.133491\n",
      "[500]\tvalid_0's binary_logloss: 0.133417\n",
      "[600]\tvalid_0's binary_logloss: 0.133345\n",
      "[700]\tvalid_0's binary_logloss: 0.133313\n",
      "[800]\tvalid_0's binary_logloss: 0.133312\n",
      "[900]\tvalid_0's binary_logloss: 0.133293\n",
      "[1000]\tvalid_0's binary_logloss: 0.133278\n",
      "[1100]\tvalid_0's binary_logloss: 0.133272\n",
      "[1200]\tvalid_0's binary_logloss: 0.133261\n",
      "[1300]\tvalid_0's binary_logloss: 0.133244\n",
      "[1400]\tvalid_0's binary_logloss: 0.133276\n",
      "Early stopping, best iteration is:\n",
      "[1283]\tvalid_0's binary_logloss: 0.133236\n",
      "Start predicting...\n",
      "Final score for fold 0 : 0.133236338331 Transformed score: 0.154003813434 \n",
      " Time it took to train and predict on fold: 66.12506580352783 \n",
      "\n",
      "Mean target rate :  0.19124359014512396\n",
      "Mean target rate :  0.19124429867267975\n",
      "\n",
      " Start training on fold: 1\n",
      "Train until valid scores didn't improve in 200 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.154176\n",
      "[200]\tvalid_0's binary_logloss: 0.139256\n",
      "[300]\tvalid_0's binary_logloss: 0.138617\n",
      "[400]\tvalid_0's binary_logloss: 0.138559\n",
      "[500]\tvalid_0's binary_logloss: 0.138542\n",
      "[600]\tvalid_0's binary_logloss: 0.138516\n",
      "[700]\tvalid_0's binary_logloss: 0.138563\n",
      "Early stopping, best iteration is:\n",
      "[598]\tvalid_0's binary_logloss: 0.138516\n",
      "Start predicting...\n",
      "Final score for fold 1 : 0.138515515798 Transformed score: 0.16872445326 \n",
      " Time it took to train and predict on fold: 30.562898874282837 \n",
      "\n",
      "Mean target rate :  0.19124359014512396\n",
      "Mean target rate :  0.19124429867267975\n",
      "\n",
      " Start training on fold: 2\n",
      "Train until valid scores didn't improve in 200 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.150064\n",
      "[200]\tvalid_0's binary_logloss: 0.134973\n",
      "[300]\tvalid_0's binary_logloss: 0.134334\n",
      "[400]\tvalid_0's binary_logloss: 0.134288\n",
      "[500]\tvalid_0's binary_logloss: 0.13422\n",
      "[600]\tvalid_0's binary_logloss: 0.134147\n",
      "[700]\tvalid_0's binary_logloss: 0.1341\n",
      "[800]\tvalid_0's binary_logloss: 0.134101\n",
      "[900]\tvalid_0's binary_logloss: 0.134072\n",
      "[1000]\tvalid_0's binary_logloss: 0.134108\n",
      "[1100]\tvalid_0's binary_logloss: 0.13413\n",
      "Early stopping, best iteration is:\n",
      "[900]\tvalid_0's binary_logloss: 0.134072\n",
      "Start predicting...\n",
      "Final score for fold 2 : 0.13407194451 Transformed score: 0.158786187442 \n",
      " Time it took to train and predict on fold: 44.37501883506775 \n",
      "\n",
      "Mean target rate :  0.19124365247373792\n",
      "Mean target rate :  0.1912461881454527\n",
      "\n",
      " Start training on fold: 3\n",
      "Train until valid scores didn't improve in 200 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.14944\n",
      "[200]\tvalid_0's binary_logloss: 0.134533\n",
      "[300]\tvalid_0's binary_logloss: 0.134096\n",
      "[400]\tvalid_0's binary_logloss: 0.134073\n",
      "[500]\tvalid_0's binary_logloss: 0.133979\n",
      "[600]\tvalid_0's binary_logloss: 0.134024\n",
      "[700]\tvalid_0's binary_logloss: 0.133971\n",
      "[800]\tvalid_0's binary_logloss: 0.133975\n",
      "[900]\tvalid_0's binary_logloss: 0.134038\n",
      "Early stopping, best iteration is:\n",
      "[775]\tvalid_0's binary_logloss: 0.133945\n",
      "Start predicting...\n",
      "Final score for fold 3 : 0.133944765247 Transformed score: 0.153227031633 \n",
      " Time it took to train and predict on fold: 38.66101002693176 \n",
      "\n",
      "Mean target rate :  0.19124365247373792\n",
      "Mean target rate :  0.1912461881454527\n",
      "\n",
      " Start training on fold: 4\n",
      "Train until valid scores didn't improve in 200 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.154722\n",
      "[200]\tvalid_0's binary_logloss: 0.139296\n",
      "[300]\tvalid_0's binary_logloss: 0.138711\n",
      "[400]\tvalid_0's binary_logloss: 0.13863\n",
      "[500]\tvalid_0's binary_logloss: 0.13864\n",
      "[600]\tvalid_0's binary_logloss: 0.138625\n",
      "[700]\tvalid_0's binary_logloss: 0.138648\n",
      "Early stopping, best iteration is:\n",
      "[586]\tvalid_0's binary_logloss: 0.13862\n",
      "Start predicting...\n",
      "Final score for fold 4 : 0.138620249646 Transformed score: 0.149764853106 \n",
      " Time it took to train and predict on fold: 31.251219511032104 \n",
      "\n",
      "Mean target rate :  0.19124365247373792\n",
      "Mean target rate :  0.1912461881454527\n",
      "\n",
      " Start training on fold: 5\n",
      "Train until valid scores didn't improve in 200 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152348\n",
      "[200]\tvalid_0's binary_logloss: 0.137092\n",
      "[300]\tvalid_0's binary_logloss: 0.13655\n",
      "[400]\tvalid_0's binary_logloss: 0.136509\n",
      "[500]\tvalid_0's binary_logloss: 0.136504\n",
      "[600]\tvalid_0's binary_logloss: 0.136498\n",
      "Early stopping, best iteration is:\n",
      "[444]\tvalid_0's binary_logloss: 0.136484\n",
      "Start predicting...\n",
      "Final score for fold 5 : 0.136484407208 Transformed score: 0.156818145331 \n",
      " Time it took to train and predict on fold: 25.96168327331543 \n",
      "\n",
      "Mean target rate :  0.19124365247373792\n",
      "Mean target rate :  0.1912461881454527\n",
      "\n",
      " Start training on fold: 6\n",
      "Train until valid scores didn't improve in 200 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.15278\n",
      "[200]\tvalid_0's binary_logloss: 0.136997\n",
      "[300]\tvalid_0's binary_logloss: 0.136359\n",
      "[400]\tvalid_0's binary_logloss: 0.136279\n",
      "[500]\tvalid_0's binary_logloss: 0.13631\n",
      "[600]\tvalid_0's binary_logloss: 0.136301\n",
      "Early stopping, best iteration is:\n",
      "[479]\tvalid_0's binary_logloss: 0.136214\n",
      "Start predicting...\n",
      "Final score for fold 6 : 0.136214416219 Transformed score: 0.157915683066 \n",
      " Time it took to train and predict on fold: 27.042507648468018 \n",
      "\n",
      "Mean target rate :  0.19124365247373792\n",
      "Mean target rate :  0.19124373774776737\n",
      "\n",
      " Start training on fold: 7\n",
      "Train until valid scores didn't improve in 200 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.149659\n",
      "[200]\tvalid_0's binary_logloss: 0.134173\n",
      "[300]\tvalid_0's binary_logloss: 0.133523\n",
      "[400]\tvalid_0's binary_logloss: 0.133438\n",
      "[500]\tvalid_0's binary_logloss: 0.133359\n",
      "[600]\tvalid_0's binary_logloss: 0.133349\n",
      "[700]\tvalid_0's binary_logloss: 0.133292\n",
      "[800]\tvalid_0's binary_logloss: 0.133337\n",
      "Early stopping, best iteration is:\n",
      "[698]\tvalid_0's binary_logloss: 0.133292\n",
      "Start predicting...\n",
      "Final score for fold 7 : 0.133292058375 Transformed score: 0.160547408313 \n",
      " Time it took to train and predict on fold: 37.456759452819824 \n",
      "\n",
      "Mean target rate :  0.19124365247373792\n",
      "Mean target rate :  0.19124373774776737\n",
      "\n",
      " Start training on fold: 8\n",
      "Train until valid scores didn't improve in 200 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152517\n",
      "[200]\tvalid_0's binary_logloss: 0.136861\n",
      "[300]\tvalid_0's binary_logloss: 0.136188\n",
      "[400]\tvalid_0's binary_logloss: 0.136128\n",
      "[500]\tvalid_0's binary_logloss: 0.136096\n",
      "[600]\tvalid_0's binary_logloss: 0.136111\n",
      "[700]\tvalid_0's binary_logloss: 0.136123\n",
      "Early stopping, best iteration is:\n",
      "[500]\tvalid_0's binary_logloss: 0.136096\n",
      "Start predicting...\n",
      "Final score for fold 8 : 0.13609641058 Transformed score: 0.15374465793 \n",
      " Time it took to train and predict on fold: 28.528101444244385 \n",
      "\n",
      "Mean target rate :  0.19124365247373792\n",
      "Mean target rate :  0.19124373774776737\n",
      "\n",
      " Start training on fold: 9\n",
      "Train until valid scores didn't improve in 200 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152753\n",
      "[200]\tvalid_0's binary_logloss: 0.137223\n",
      "[300]\tvalid_0's binary_logloss: 0.13656\n",
      "[400]\tvalid_0's binary_logloss: 0.136464\n",
      "[500]\tvalid_0's binary_logloss: 0.136375\n",
      "[600]\tvalid_0's binary_logloss: 0.136314\n",
      "[700]\tvalid_0's binary_logloss: 0.136314\n",
      "[800]\tvalid_0's binary_logloss: 0.136301\n",
      "[900]\tvalid_0's binary_logloss: 0.136292\n",
      "[1000]\tvalid_0's binary_logloss: 0.136309\n",
      "Early stopping, best iteration is:\n",
      "[863]\tvalid_0's binary_logloss: 0.136269\n",
      "Start predicting...\n",
      "Final score for fold 9 : 0.136269174698 Transformed score: 0.160160678752 \n",
      " Time it took to train and predict on fold: 50.64533042907715 \n",
      "\n",
      "Mean logloss for model in 10-folds SKF: 0.135674528061 \n",
      " Mean logloss for transformed predictions: 0.157369291227 \n",
      "\n",
      "Predicting on test set with LightGBM.\n"
     ]
    }
   ],
   "source": [
    "savename = 'stacking_TrainValidOversample_testInverse'\n",
    "\n",
    "X_test = testOOF_transform(X_test, inverse = True)\n",
    "oof_train, oof_test = lgb_foldrun_test_oversample(X_train, y_train, X_test, lgb_params, savename, False)\n",
    "predict_test_lgbm(oof_test, savename, transform_preds = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/submissions/'\n",
    "s1 = pd.read_csv(src + 'stacking_TrainValidOversample_testInverse.csv')\n",
    "s2 = pd.read_csv(src + 'stacking_ValidOversample.csv')\n",
    "s3 = pd.read_csv(src + 'test_preds_mod_xgbstack1_0.1754_20170604_1555.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
