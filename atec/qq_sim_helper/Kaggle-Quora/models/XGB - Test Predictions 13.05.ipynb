{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import multiprocessing\n",
    "import difflib\n",
    "import time\n",
    "import gc\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.metrics import log_loss\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from scipy.spatial.distance import cosine, correlation, canberra, chebyshev, minkowski, jaccard, euclidean\n",
    "\n",
    "from models_utils_xgb import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test():\n",
    "    feats_src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/data/features/uncleaned/'\n",
    "    feats_src2 = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/data/features/NER/'\n",
    "    \n",
    "    keras_q1 = np.load(feats_src2 + 'q1test_NER_128len.npy')\n",
    "    keras_q2 = np.load(feats_src2 + 'q2test_NER_128len.npy')\n",
    "    xgb_feats = pd.read_csv(feats_src + '/the_1owl/owl_test.csv')\n",
    "    abhishek_feats = pd.read_csv(feats_src + 'abhishek/test_features.csv',\n",
    "                              encoding = 'ISO-8859-1').iloc[:, 2:]\n",
    "    text_feats = pd.read_csv(feats_src + 'other_features/text_features_test.csv',\n",
    "                            encoding = 'ISO-8859-1')\n",
    "    img_feats = pd.read_csv(feats_src + 'other_features/img_features_test.csv')\n",
    "    srk_feats = pd.read_csv(feats_src + 'srk/SRK_grams_features_test.csv')\n",
    "    \n",
    "    mephisto_feats = pd.read_csv('../../data/features/lemmatized_fullclean/test_mephistopeheles_features.csv').iloc[:, 6:]\n",
    "    turkewitz_feats = pd.read_csv('../../data/features/lemmatized_fullclean/test_turkewitz_features_fullcleanSTEMMED.csv')\n",
    "    turkewitz_feats = turkewitz_feats[['q1_freq', 'q2_freq']]\n",
    "    turkewitz_feats['freq_sum'] = turkewitz_feats.q1_freq + turkewitz_feats.q2_freq\n",
    "    turkewitz_feats['freq_diff'] = turkewitz_feats.q1_freq - turkewitz_feats.q2_freq\n",
    "    turkewitz_feats['freq_mult'] = turkewitz_feats.q1_freq * turkewitz_feats.q2_freq\n",
    "    turkewitz_feats['freq_div'] = turkewitz_feats.q1_freq / turkewitz_feats.q2_freq\n",
    "\n",
    "    xgb_feats.drop(['z_len1', 'z_len2', 'z_word_len1', 'z_word_len2'], axis = 1, inplace = True)\n",
    "    xgb_feats = xgb_feats.iloc[:, 5:]\n",
    "    \n",
    "    df = pd.concat([xgb_feats, abhishek_feats, text_feats, img_feats, \n",
    "                               turkewitz_feats, mephisto_feats], axis = 1)\n",
    "    del xgb_feats, abhishek_feats, text_feats, img_feats, turkewitz_feats, mephisto_feats\n",
    "    gc.collect()\n",
    "    \n",
    "    df = drop_duplicate_cols(df)\n",
    "    keras_q1 = pd.DataFrame(keras_q1)\n",
    "    keras_q2 = pd.DataFrame(keras_q2)\n",
    "    keras_q1.columns = ['question1_{}'.format(i) for i in range(keras_q1.shape[1])]\n",
    "    keras_q2.columns = ['question2_{}'.format(i) for i in range(keras_q2.shape[1])]\n",
    "    X = pd.concat([keras_q1, keras_q2, df], axis = 1)\n",
    "    \n",
    "    colnames_list = X.columns.tolist()\n",
    "    colnames_list[300] = 'len_char_q1_other'\n",
    "    colnames_list[301] = 'len_char_q2_other'\n",
    "    X.columns = colnames_list\n",
    "    print('Test data shape:', X.shape)\n",
    "    X = X.astype('float32')\n",
    "    return X\n",
    "\n",
    "def predict_test(X_test, model_name):\n",
    "    print('Predicting on test set.')\n",
    "    gbm = xgb.Booster(model_file = 'saved_models/XGB/{}.txt'.format(model_name))\n",
    "    X_test = xgb.DMatrix(X_test)\n",
    "    test_preds = gbm.predict(X_test)\n",
    "    sub_src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/submissions/'\n",
    "    sample_sub = pd.read_csv(sub_src + 'sample_submission.csv')\n",
    "    sample_sub['is_duplicate'] = test_preds\n",
    "    sample_sub.is_duplicate = sample_sub.is_duplicate.apply(transform)\n",
    "    sample_sub.to_csv(sub_src + '{}.csv'.format(model_name), index = False)\n",
    "    return\n",
    "\n",
    "\n",
    "def get_transformations_features(transformations_src, mode = 'train'):\n",
    "    print('Adding features based on data transformations.')\n",
    "    lsa10tr_3grams_q1 = np.load(transformations_src + '{}_lsa10_3grams.npy'.format(mode))[0]\n",
    "    lsa10tr_3grams_q2 = np.load(transformations_src + '{}_lsa10_3grams.npy'.format(mode))[1]\n",
    "    \n",
    "    transforms_feats = pd.DataFrame()\n",
    "    transforms_feats['cosine'] = [cosine(x, y) for (x,y) in zip(lsa10tr_3grams_q1, lsa10tr_3grams_q2)]\n",
    "    transforms_feats['correlation'] = [correlation(x, y) for (x,y) in zip(lsa10tr_3grams_q1, lsa10tr_3grams_q2)]\n",
    "    transforms_feats['jaccard'] = [jaccard(x, y) for (x,y) in zip(lsa10tr_3grams_q1, lsa10tr_3grams_q2)]\n",
    "    transforms_feats['euclidean'] = [euclidean(x, y) for (x,y) in zip(lsa10tr_3grams_q1, lsa10tr_3grams_q2)]\n",
    "    transforms_feats['minkowski'] = [minkowski(x, y, 3) for (x,y) in zip(lsa10tr_3grams_q1, lsa10tr_3grams_q2)]\n",
    "    return transforms_feats\n",
    "\n",
    "def get_doc2vec_features(doc2vec_src, mode = 'train'):\n",
    "    print('Adding features based on Doc2Vec distances.')\n",
    "    doc2vec_pre_q1 = np.load(doc2vec_src + '{}_q1_doc2vec_vectors_pretrained.npy'.format(mode))\n",
    "    doc2vec_pre_q2 = np.load(doc2vec_src + '{}_q2_doc2vec_vectors_pretrained.npy'.format(mode))\n",
    "    doc2vec_quora_q1 = np.load(doc2vec_src + '{}_q1_doc2vec_vectors_trainquora.npy'.format(mode))\n",
    "    doc2vec_quora_q2 = np.load(doc2vec_src + '{}_q2_doc2vec_vectors_trainquora.npy'.format(mode))\n",
    "    \n",
    "    d2v_feats_pretrained = pd.DataFrame()\n",
    "    d2v_feats_pretrained['cosine'] = [cosine(x, y) for (x,y) in zip(doc2vec_pre_q1, doc2vec_pre_q2)]\n",
    "    d2v_feats_pretrained['correlation'] = [correlation(x, y) for (x,y) in zip(doc2vec_pre_q1, doc2vec_pre_q2)]\n",
    "    d2v_feats_pretrained['jaccard'] = [jaccard(x, y) for (x,y) in zip(doc2vec_pre_q1, doc2vec_pre_q2)]\n",
    "    d2v_feats_pretrained['euclidean'] = [euclidean(x, y) for (x,y) in zip(doc2vec_pre_q1, doc2vec_pre_q2)]\n",
    "    d2v_feats_pretrained['minkowski'] = [minkowski(x, y, 3) for (x,y) in zip(doc2vec_pre_q1, doc2vec_pre_q2)]\n",
    "    \n",
    "    d2v_feats_quora = pd.DataFrame()\n",
    "    d2v_feats_quora['cosine'] = [cosine(x, y) for (x,y) in zip(doc2vec_quora_q1, doc2vec_quora_q2)]\n",
    "    d2v_feats_quora['correlation'] = [correlation(x, y) for (x,y) in zip(doc2vec_quora_q1, doc2vec_quora_q2)]\n",
    "    d2v_feats_quora['jaccard'] = [jaccard(x, y) for (x,y) in zip(doc2vec_quora_q1, doc2vec_quora_q2)]\n",
    "    d2v_feats_quora['euclidean'] = [euclidean(x, y) for (x,y) in zip(doc2vec_quora_q1, doc2vec_quora_q2)]\n",
    "    d2v_feats_quora['minkowski'] = [minkowski(x, y, 3) for (x,y) in zip(doc2vec_quora_q1, doc2vec_quora_q2)]\n",
    "    return d2v_feats_pretrained, d2v_feats_quora\n",
    "\n",
    "def labelcount_encode(df2, cols):\n",
    "    df = df2.copy()\n",
    "    categorical_features = cols\n",
    "    new_df = pd.DataFrame()\n",
    "    for cat_feature in categorical_features:\n",
    "        cat_feature_value_counts = df[cat_feature].value_counts()\n",
    "        value_counts_list = cat_feature_value_counts.index.tolist()\n",
    "        value_counts_range_rev = list(reversed(range(len(cat_feature_value_counts)))) # for ascending ordering\n",
    "        value_counts_range = list(range(len(cat_feature_value_counts))) # for descending ordering\n",
    "        labelcount_dict = dict(zip(value_counts_list, value_counts_range))\n",
    "        new_df[cat_feature] = df[cat_feature].map(labelcount_dict)\n",
    "    return new_df\n",
    "\n",
    "def count_encode(df2, cols):\n",
    "    df = df2.copy()\n",
    "    categorical_features = cols\n",
    "    new_df = pd.DataFrame()\n",
    "    for i in categorical_features:\n",
    "        new_df[i] = df[i].astype('object').replace(df[i].value_counts())\n",
    "    return new_df\n",
    "\n",
    "def bin_numerical(df2, cols, step):\n",
    "    df = df2.copy()\n",
    "    numerical_features = cols\n",
    "    new_df = pd.DataFrame()\n",
    "    for i in numerical_features:\n",
    "        feature_range = np.arange(0, np.max(df[i]), step)\n",
    "        new_df[i] = np.digitize(df[i], feature_range, right=True)\n",
    "    return new_df\n",
    "\n",
    "def drop_duplicate_cols(df):\n",
    "    dfc = df.iloc[0:10000,:]\n",
    "    dfc = dfc.T.drop_duplicates().T\n",
    "    duplicate_cols = sorted(list(set(df.columns).difference(set(dfc.columns))))\n",
    "    print('Dropping duplicate columns:', duplicate_cols)\n",
    "    df.drop(duplicate_cols, axis = 1, inplace = True)\n",
    "    print('Final shape:', df.shape)\n",
    "    del dfc\n",
    "    gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_new_feats():\n",
    "    \n",
    "    print('Creating additional grouping features.')\n",
    "    turkewitz_feats = pd.read_csv('/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/data/features/lemmatized_fullclean/test_turkewitz_features_fullcleanSTEMMED.csv')\n",
    "    turkewitz_feats = turkewitz_feats[['q1_freq', 'q2_freq']]\n",
    "    \n",
    "    ff1 = turkewitz_feats.groupby(['q2_freq'])['q1_freq'].transform('sum')\n",
    "    ff2 = turkewitz_feats.groupby(['q1_freq'])['q2_freq'].transform('sum')\n",
    "    ff1 = ff1 / np.max(ff1)\n",
    "    ff2 = ff2 / np.max(ff2)\n",
    "    ff1m = turkewitz_feats.groupby(['q2_freq'])['q1_freq'].transform('mean')\n",
    "    ff2m = turkewitz_feats.groupby(['q1_freq'])['q2_freq'].transform('mean')\n",
    "    ff1m = ff1m / np.max(ff1m)\n",
    "    ff2m = ff2m / np.max(ff2m)\n",
    "    gr_feats = pd.DataFrame()\n",
    "    gr_feats['ff1'] = ff1\n",
    "    gr_feats['ff2'] = ff2\n",
    "    gr_feats['ff1m'] = ff1m\n",
    "    gr_feats['ff2m'] = ff2m\n",
    "\n",
    "    test_c = count_encode(turkewitz_feats, ['q1_freq', 'q2_freq'])\n",
    "    test_c.q1_freq = test_c.q1_freq / np.max(test_c.q1_freq)\n",
    "    test_c.q2_freq = test_c.q2_freq / np.max(test_c.q2_freq)\n",
    "    test_c.rename(columns = {'q1_freq': 'q1_freq_normalized', 'q2_freq': 'q2_freq_normalized'}, inplace = True)\n",
    "\n",
    "    src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/scripts/features/'\n",
    "    network_feats =  pd.read_csv(src + 'test_networkfeats_fullclean.csv')\n",
    "    textacy1_feats = pd.read_csv(src + 'test_textacy_similarity_feats.csv')\n",
    "\n",
    "    new_feats = pd.concat([test_c, gr_feats, network_feats, textacy1_feats, turkewitz_feats], axis = 1)\n",
    "    new_feats['q1_deg_by_freq'] = new_feats.groupby(['q1_freq'])['q1_degrees'].transform('mean')\n",
    "    new_feats['q2_deg_by_freq'] = new_feats.groupby(['q2_freq'])['q2_degrees'].transform('mean')\n",
    "    new_feats['q1_deg_by_freq2'] = new_feats.groupby(['q1_freq'])['q2_degrees'].transform('mean')\n",
    "    new_feats['q2_deg_by_freq1'] = new_feats.groupby(['q2_freq'])['q1_degrees'].transform('mean')\n",
    "    new_feats['q1_clust_by_freq'] = new_feats.groupby(['q1_freq'])['q1_cluster'].transform('mean')\n",
    "    new_feats['q2_clust_by_freq'] = new_feats.groupby(['q2_freq'])['q2_cluster'].transform('mean')\n",
    "    new_feats['q1_clust_by_freq2'] = new_feats.groupby(['q1_freq'])['q2_cluster'].transform('mean')\n",
    "    new_feats['q2_clust_by_freq1'] = new_feats.groupby(['q2_freq'])['q1_cluster'].transform('mean')\n",
    "    new_feats['q1_deg_by_freq_inv'] = new_feats.groupby(['q1_degrees'])['q1_freq'].transform('mean')\n",
    "    new_feats['q2_deg_by_freq_inv'] = new_feats.groupby(['q2_degrees'])['q2_freq'].transform('mean')\n",
    "    new_feats['q1_deg_by_freq2_inv'] = new_feats.groupby(['q2_degrees'])['q1_freq'].transform('mean')\n",
    "    new_feats['q2_deg_by_freq1_inv'] = new_feats.groupby(['q1_degrees'])['q2_freq'].transform('mean')\n",
    "    new_feats['q1_clust_by_freq_inv'] = new_feats.groupby(['q1_cluster'])['q1_freq'].transform('mean')\n",
    "    new_feats['q2_clust_by_freq_inv'] = new_feats.groupby(['q2_cluster'])['q2_freq'].transform('mean')\n",
    "    new_feats['q1_clust_by_freq2_inv'] = new_feats.groupby(['q2_cluster'])['q1_freq'].transform('mean')\n",
    "    new_feats['q2_clust_by_freq1_inv'] = new_feats.groupby(['q1_cluster'])['q2_freq'].transform('mean')\n",
    "    new_feats.drop(turkewitz_feats.columns.tolist(), axis = 1, inplace = True)\n",
    "\n",
    "    del test_c, gr_feats, network_feats, textacy1_feats, turkewitz_feats\n",
    "    gc.collect()\n",
    "    return new_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/scripts/features/'\n",
    "\n",
    "X_test = get_test()\n",
    "new_feats = get_new_feats()\n",
    "\n",
    "networks_tony = pd.read_pickle(src + 'test_fullnetworkfeatsTony.pkl')\n",
    "networks_weighted = pd.read_pickle(src + 'test_networkfeats_weighted.pkl')\n",
    "\n",
    "col_dict = {\n",
    "    'q1_cluster': 'q1_cluster_tony',\n",
    "    'q1_degrees': 'q1_degrees_tony',\n",
    "    'q1_squared_cluster': 'q1_squared_cluster_tony',\n",
    "    'q1_triangles_cluster': 'q1_triangles_cluster_tony',\n",
    "    'q2_cluster': 'q2_cluster_tony',\n",
    "    'q2_degrees': 'q2_degrees_tony',\n",
    "    'q2_squared_cluster': 'q2_squared_cluster_tony',\n",
    "    'q2_triangles_cluster': 'q2_triangles_cluster_tony'\n",
    "}\n",
    "\n",
    "networks_tony.rename(columns = col_dict, inplace = True)\n",
    "\n",
    "cv_svd50_dist = pd.read_csv(src + 'test_SVD_CV1gram_50dim.csv')\n",
    "cv_lsa50_dist = pd.read_csv(src + 'test_LSA_CV1gram_50dim.csv')\n",
    "\n",
    "tfidf_svd50_dist = pd.read_csv(src + 'test_SVD_TFIDF_3grams_words_50dim.csv')\n",
    "tfidf_lsa50_dist = pd.read_csv(src + 'test_LSA_TFIDF_3grams_words_50dim.csv')\n",
    "\n",
    "d2v_pre = pd.read_csv(src + 'test_doc2vec_pretrained_distances.csv')\n",
    "d2v_quora = pd.read_csv(src + 'test_doc2vec_quoratrain_distances.csv')\n",
    "transforms = pd.read_csv(src + 'test_SVDLSA_CV1gram_distances.csv')\n",
    "\n",
    "X_test = pd.concat([X_test, new_feats, networks_tony, networks_weighted,\n",
    "                     cv_svd50_dist, cv_lsa50_dist, tfidf_svd50_dist, tfidf_lsa50_dist,\n",
    "                     d2v_pre, d2v_quora, transforms], axis = 1)\n",
    "\n",
    "cols_to_drop = ['counts_max_network_weighted', 'counts_min_network_weighted', 'diff_counts_network_weighted', 'diff_degrees_network_weighted', 'diff_triangles_cluster_network_weighted', 'exactly_same', 'jaccard_distance_test_LSA_TFIDF_3grams_words_50dim', 'max_degrees_network_weighted', 'max_triangles_cluster_network_weighted', 'min_degrees_network_weighted', 'min_triangles_cluster_network_weighted', 'mult_counts_network_weighted', 'q1_counts_network_weighted', 'q1_degrees_network_weighted', 'q1_triangles_cluster_network_weighted', 'q2_counts_network_weighted', 'q2_degrees_network_weighted', 'q2_triangles_cluster_network_weighted', 'question1_100', 'question1_101', 'question1_102', 'question1_103', 'question1_104', 'question1_105', 'question1_106', 'question1_107', 'question1_108', 'question1_109', 'question1_110', 'question1_111', 'question1_112', 'question1_113', 'question1_114', 'question1_115', 'question1_116', 'question1_117', 'question1_118', 'question1_119', 'question1_120', 'question1_121', 'question1_122', 'question1_123', 'question1_124', 'question1_125', 'question1_126', 'question1_127', 'question1_68', 'question1_69', 'question1_70', 'question1_71', 'question1_72', 'question1_73', 'question1_74', 'question1_75', 'question1_76', 'question1_77', 'question1_78', 'question1_79', 'question1_80', 'question1_81', 'question1_82', 'question1_83', 'question1_84', 'question1_85', 'question1_86', 'question1_87', 'question1_88', 'question1_89', 'question1_90', 'question1_91', 'question1_92', 'question1_93', 'question1_94', 'question1_95', 'question1_96', 'question1_97', 'question1_98', 'question1_99', 'question2_103', 'question2_104', 'question2_106', 'question2_108', 'question2_109', 'question2_110', 'question2_112', 'question2_113', 'question2_114', 'question2_115', 'question2_116', 'question2_118', 'question2_119', 'question2_120', 'question2_121', 'question2_122', 'question2_123', 'question2_126', 'question2_127', 'question2_81', 'question2_83', 'question2_87', 'question2_88', 'question2_89', 'question2_96', 'sum_counts_network_weighted', 'sum_degrees_network_weighted', 'sum_triangles_cluster_network_weighted']\n",
    "X_test.drop(cols_to_drop, axis = 1, inplace = True)\n",
    "X_test = X_test.astype('float32')\n",
    "print('Final shape:', X_test.shape)\n",
    "\n",
    "X_test.to_pickle('Xtest_916cols.pkl')\n",
    "\n",
    "del new_feats, networks_tony, networks_weighted, cv_svd50_dist, cv_lsa50_dist, \\\n",
    "tfidf_svd50_dist, tfidf_lsa50_dist, d2v_pre, d2v_quora, transforms\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = pd.read_pickle('Xtest_500bestCols.pkl')\n",
    "predict_test(X_test, 'XGB_new_NetworkFeats_experiments_500feats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
